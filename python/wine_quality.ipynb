{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "\n",
    "from Model_Parent import *\n",
    "from Model_Parent_2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../cleaned_data/winequality-white_fixed.csv\", index_col=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check to make sure that no columns have perfect colinearity\n",
    "corr_mat = df.corr(method='pearson')\n",
    "sns.heatmap(corr_mat, cmap='vlag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.267785</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.132832</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.096626</td>\n",
       "      <td>0.121662</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.204176</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.089021</td>\n",
       "      <td>0.076655</td>\n",
       "      <td>0.192575</td>\n",
       "      <td>0.077694</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.113497</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.191638</td>\n",
       "      <td>0.368910</td>\n",
       "      <td>0.150183</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.114458</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.094955</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.236659</td>\n",
       "      <td>0.104685</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.163462</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.234339</td>\n",
       "      <td>0.030461</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.032641</td>\n",
       "      <td>0.069686</td>\n",
       "      <td>0.206497</td>\n",
       "      <td>0.044342</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0          0.307692          0.186275     0.216867        0.308282   0.106825   \n",
       "1          0.240385          0.215686     0.204819        0.015337   0.118694   \n",
       "2          0.413462          0.196078     0.240964        0.096626   0.121662   \n",
       "3          0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "4          0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893       0.230769          0.127451     0.174699        0.015337   0.089021   \n",
       "4894       0.269231          0.235294     0.216867        0.113497   0.112760   \n",
       "4895       0.259615          0.156863     0.114458        0.009202   0.094955   \n",
       "4896       0.163462          0.205882     0.180723        0.007669   0.038576   \n",
       "4897       0.211538          0.127451     0.228916        0.003067   0.032641   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0                0.149826              0.373550  0.267785  0.254545   \n",
       "1                0.041812              0.285383  0.132832  0.527273   \n",
       "2                0.097561              0.204176  0.154039  0.490909   \n",
       "3                0.156794              0.410673  0.163678  0.427273   \n",
       "4                0.156794              0.410673  0.163678  0.427273   \n",
       "...                   ...                   ...       ...       ...   \n",
       "4893             0.076655              0.192575  0.077694  0.500000   \n",
       "4894             0.191638              0.368910  0.150183  0.390909   \n",
       "4895             0.097561              0.236659  0.104685  0.245455   \n",
       "4896             0.062718              0.234339  0.030461  0.563636   \n",
       "4897             0.069686              0.206497  0.044342  0.490909   \n",
       "\n",
       "      sulphates   alcohol   quality  \n",
       "0      0.267442  0.129032  0.500000  \n",
       "1      0.313953  0.241935  0.500000  \n",
       "2      0.255814  0.338710  0.500000  \n",
       "3      0.209302  0.306452  0.500000  \n",
       "4      0.209302  0.306452  0.500000  \n",
       "...         ...       ...       ...  \n",
       "4893   0.325581  0.516129  0.500000  \n",
       "4894   0.279070  0.258065  0.333333  \n",
       "4895   0.279070  0.225806  0.500000  \n",
       "4896   0.186047  0.774194  0.666667  \n",
       "4897   0.116279  0.612903  0.500000  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing old columns names\n",
    "df_col_names = list(df.columns)\n",
    "\n",
    "# Scaling data by min and max in the range of 0 to 1\n",
    "scaler = MinMaxScaler(feature_range = [0, 1])\n",
    "tmp = scaler.fit_transform(df)\n",
    "\n",
    "# Converting scaled values back into dataframe\n",
    "df = pd.DataFrame(tmp, columns=df_col_names)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Data in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 07s]\n",
      "val_loss: 0.040519386529922485\n",
      "\n",
      "Best val_loss So Far: 0.01709730364382267\n",
      "Total elapsed time: 00h 01m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "115/115 [==============================] - 1s 2ms/step - loss: 0.1207 - mean_squared_error: 0.1207\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0539 - mean_squared_error: 0.0539\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0301 - mean_squared_error: 0.0301\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0253 - mean_squared_error: 0.0253\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
      "Epoch 8/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0194 - mean_squared_error: 0.0194\n",
      "Epoch 9/10\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0186 - mean_squared_error: 0.0186\n",
      "Epoch 10/10\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.0182 - mean_squared_error: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 01:30:04.577863: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./auto_keras/best_model/assets\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.0168 - mean_squared_error: 0.0168\n",
      "[0.016836633905768394, 0.016836633905768394]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 11)]              0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 11)               0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 11)               23        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                384       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,496\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 23\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Using AutoKeras output to help us tune our parameters\n",
    "# Can adjust hyperpameters, activation functions, and layer stucture based on our findings\n",
    "\n",
    "auto_tune = ak.StructuredDataRegressor(max_trials=10, \n",
    "                                       overwrite=True,\n",
    "                                       loss='mean_squared_error',\n",
    "                                       output_dim=1,\n",
    "                                       project_name='auto_keras'\n",
    "                                       )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "auto_tune.fit(X_train, y_train, validation_split = 0.15, epochs = 10)\n",
    "y_hat = auto_tune.predict(X_test)\n",
    "print(auto_tune.evaluate(X_test, y_test))\n",
    "\n",
    "auto_tune_mod = auto_tune.export_model()\n",
    "print(auto_tune_mod.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of folds in cross validation (kfolds method)\n",
    "cv_folds = 5\n",
    "\n",
    "# Defining number of epochs\n",
    "epo = 50\n",
    "\n",
    "# Defining batch size\n",
    "bs = 32\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 2 values in the list are neurons of first 2 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 11)                132       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0474\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0221\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0176\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 828us/step - loss: 0.0174\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0172\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0171\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0160\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 11)                132       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0376\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0193\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0189\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0183\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0178\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0174\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 830us/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0160\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 11)                132       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0253\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0208\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0197\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0188\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0159\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 11)                132       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0274\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0222\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0206\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0200\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0194\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0190\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0185\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0157\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+---------------------+-------------------+-----------+-----------+\n",
      "|        r2_cv        |       r2_bar      |    AIC    |    BIC    |\n",
      "+---------------------+-------------------+-----------+-----------+\n",
      "| 0.27008482779229964 | 0.268591242418435 | -4036.316 | -4036.316 |\n",
      "+---------------------+-------------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Fri, 01 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        23:32:50   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0226\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0216\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0215\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 828us/step - loss: 0.0215\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0214\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0213\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0213\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0213\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 830us/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0211\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 703us/step - loss: 0.0267\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0218\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0217\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0217\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0217\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0216\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0216\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0216\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0215\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0215\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0215\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0215\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0214\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0214\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0214\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0214\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 726us/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 724us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0211\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 716us/step - loss: 0.0496\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0235\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0220\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0218\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0218\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0218\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0218\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0217\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0217\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0217\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0216\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0216\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0216\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0215\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0215\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0215\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0215\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0214\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0214\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0214\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0214\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0211\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0302\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 739us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0211\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0210\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 729us/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0210\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0209\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0209\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0209\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0208\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0208\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0208\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0208\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0208\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0207\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0207\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0207\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0207\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0207\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0206\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0207\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0206\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0207\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0206\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0206\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0206\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 716us/step - loss: 0.0207\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0206\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0206\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0206\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0206\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0206\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0206\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0206\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0206\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0206\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0206\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0206\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0387\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0222\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0216\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0216\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0216\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0215\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0214\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0214\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0211\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 717us/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 723us/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0213\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0212\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 729us/step - loss: 0.0210\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0210\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0210\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0210\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0210\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0209\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0209\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0209\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0209\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0209\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0209\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0209\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0209\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0209\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0209\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0209\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0209\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0209\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0209\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0209\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0209\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0209\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0209\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0420\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0221\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 826us/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0213\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0213\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0213\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 712us/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 826us/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0210\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0401\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0223\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0218\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0217\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0217\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.0216\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0216\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0216\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0215\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.0215\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0214\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0214\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0214\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0213\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 725us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0210\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0210\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0209\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0210\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0246\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0212\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0208\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0208\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0207\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0207\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0207\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0206\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0206\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0206\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0205\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0205\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0205\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.0205\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0205\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0205\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.0205\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0205\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0205\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0205\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0205\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0204\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0205\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0204\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0204\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0205\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0204\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0204\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0204\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0204\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0204\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0204\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0204\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0204\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0204\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0204\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0204\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0204\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0204\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0204\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 896us/step - loss: 0.0294\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0210\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0210\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0209\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0209\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0209\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0209\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0209\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0209\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0209\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0209\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0209\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0208\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0208\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0209\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0208\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0209\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0208\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0208\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0209\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0208\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0209\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0208\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0208\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0208\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0208\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0208\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0218\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0209\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0206\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0202\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0196\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0193\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0189\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0181\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0172\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0171\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0163\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0210\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0205\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0200\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0196\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0192\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0188\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0184\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0169\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0163\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0259\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0212\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0208\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 720us/step - loss: 0.0204\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0199\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0195\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0192\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0188\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0163\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0202\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0194\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0189\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0180\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0177\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0174\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0172\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0169\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0167\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0166\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 737us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 737us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0160\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0363\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0193\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0190\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0184\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0181\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0178\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0173\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 709us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 730us/step - loss: 0.0160\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0317\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 739us/step - loss: 0.0205\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 701us/step - loss: 0.0202\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0198\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0194\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0191\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0188\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0185\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0182\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0177\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0175\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0173\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0172\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0171\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0167\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0167\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 719us/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 712us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 736us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 730us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 711us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0374\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0193\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0190\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0184\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0182\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0180\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0177\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0176\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0174\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0173\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0171\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0171\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0169\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0168\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0167\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0166\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0536\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0250\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0232\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0227\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0222\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0218\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 687us/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0205\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0201\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0189\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0186\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0183\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0181\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0179\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0177\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0176\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0173\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0172\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0171\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0170\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0169\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0168\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0167\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0167\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0166\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0166\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0165\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 710us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0162\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0496\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0228\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 723us/step - loss: 0.0202\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0190\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0184\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0182\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0179\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0177\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0175\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0172\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0170\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0169\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0168\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0159\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0230\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0205\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0199\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0194\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0189\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0185\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0181\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0178\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 739us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0159\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0230\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0222\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0199\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0194\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0190\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0186\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0178\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 688us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0227\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0204\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0199\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0194\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0190\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 719us/step - loss: 0.0186\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 678us/step - loss: 0.0183\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0180\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 699us/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 828us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0162\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0251\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0209\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0205\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0200\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0196\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0192\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0188\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0185\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0181\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0179\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 694us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 702us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 702us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 717us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0161\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0362\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0208\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0199\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0188\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0185\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 694us/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0159\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_62 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0296\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0209\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0205\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0201\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0197\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0194\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0190\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 712us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0181\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0178\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0159\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0212\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0206\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 700us/step - loss: 0.0201\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0196\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0191\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0187\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0184\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0178\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0161\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 701us/step - loss: 0.0258\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 723us/step - loss: 0.0199\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 730us/step - loss: 0.0195\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0181\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 730us/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 718us/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 713us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0160\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0214\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.0205\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0199\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0193\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0188\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0184\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0181\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 717us/step - loss: 0.0178\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0175\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0173\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 698us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 719us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0160\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0347\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0207\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 705us/step - loss: 0.0203\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0199\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0195\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0188\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0185\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 706us/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 719us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 710us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 737us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0158\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0235\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0223\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0205\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0198\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0193\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0188\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0184\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0181\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0178\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0175\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 724us/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0158\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_74 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0257\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0226\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0181\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0179\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0178\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0175\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0173\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0229\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0211\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0206\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0197\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0193\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0190\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0187\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0184\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0181\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0160\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0316\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0195\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0192\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0188\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0185\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0182\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0179\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0175\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0173\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0171\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 830us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0159\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0228\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0208\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0202\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0197\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0187\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0183\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0179\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0173\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_82 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0203\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0198\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0189\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0174\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0157\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0330\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0202\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0187\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0184\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0181\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0179\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0175\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0173\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0171\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 714us/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 711us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 717us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 726us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 713us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 708us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 717us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0160\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_86 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0211\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0204\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0199\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0194\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0189\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0185\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0182\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0179\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0174\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 739us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0387\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0223\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0187\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0184\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0181\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0178\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0176\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0174\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0172\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 692us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0159\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.0216\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0207\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0202\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0196\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0191\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0187\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0183\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0180\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0157\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_92 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0469\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0232\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0202\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0198\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0194\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0187\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0184\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0177\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0174\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0172\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0171\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0169\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0157\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0211\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0197\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0192\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0187\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0184\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0180\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0178\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0175\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0208\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0199\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0195\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0188\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_98 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0283\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0202\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0191\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0184\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0173\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0171\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0186\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0183\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0180\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0177\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0174\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_102 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0207\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0202\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0198\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0193\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0189\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0186\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0157\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0208\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0202\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0198\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0190\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0186\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0183\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0180\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0178\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0257\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0200\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0196\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0192\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0181\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0273\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0197\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0159\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0832\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0261\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0203\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0199\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0192\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0187\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0176\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0675\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0242\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0203\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0195\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0191\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0174\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0158\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_114 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0201\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0195\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0190\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0186\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0182\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0179\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0174\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0159\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_116 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0211\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0199\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0194\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0189\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0185\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0182\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0178\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0174\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0159\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0209\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0202\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0196\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0191\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0187\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0183\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0180\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0171\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0158\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0204\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0197\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0191\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0182\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0178\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_122 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0284\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0187\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0177\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0157\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv        |        r2_bar       |        AIC         |        BIC         |\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n",
      "|     1.0      | 0.03491413196927864 | 0.03491413196927864 | -3782.596435546875 | -3782.596435546875 |\n",
      "|     2.0      | 0.03943197261114899 | 0.03923577816111028 |   -3785.21484375   |   -3785.21484375   |\n",
      "|     3.0      | 0.25744139220861467 | 0.25713799747611554 | -4035.500732421875 | -4035.500732421875 |\n",
      "|     4.0      | 0.25788048204965053 | 0.25742556612119716 | -4034.067138671875 | -4034.067138671875 |\n",
      "|     5.0      | 0.26315254759256634 | 0.26255017894150773 | -4039.088623046875 | -4039.088623046875 |\n",
      "|     6.0      |  0.2669405991015831 |  0.2661913560507875 | -4042.156982421875 | -4042.156982421875 |\n",
      "|     7.0      |  0.2696511653152549 |  0.2687552149966884 |    -4043.78125     |    -4043.78125     |\n",
      "|     8.0      | 0.27095226328654415 |  0.2699086366695719 | -4043.489013671875 | -4043.489013671875 |\n",
      "|     9.0      |  0.2715888478499437 | 0.27039692941729887 | -4042.35498046875  | -4042.35498046875  |\n",
      "|     10.0     | 0.26830645725268454 |  0.2669592310078553 | -4035.91552734375  | -4035.91552734375  |\n",
      "|     11.0     | 0.27097987482732416 |  0.2694881209391052 | -4037.531982421875 | -4037.531982421875 |\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 2 values in the list are neurons of first 2 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0379\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_126 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0311\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0224\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0173\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_128 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0240\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0158\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.1030\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0301\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0267\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0239\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0193\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0185\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0178\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0170\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0167\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_132 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1015\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0417\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0320\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0260\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0223\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0176\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0169\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0157\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+---------------------+--------------------+-----------+-----------+\n",
      "|        r2_cv        |       r2_bar       |    AIC    |    BIC    |\n",
      "+---------------------+--------------------+-----------+-----------+\n",
      "| 0.27292136778250364 | 0.2714335866648088 | -4040.179 | -4040.179 |\n",
      "+---------------------+--------------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_134 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Fri, 01 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        23:42:28   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0698\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0294\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0273\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0255\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0226\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0211\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0210\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 739us/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.0211\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_138 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0818\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0237\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0230\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0224\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0212\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0212\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0213\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0212\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0270\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0248\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0230\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0212\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0213\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0212\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_142 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0917\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0235\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0227\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0221\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0208\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0207\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0207\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0206\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0206\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0206\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0206\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0207\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0206\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0206\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0206\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0206\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0206\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0206\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0206\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0206\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0206\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0207\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0207\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0206\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0207\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0206\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0206\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0207\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0206\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0207\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0207\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0206\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0207\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0206\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0206\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0206\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0206\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0206\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0207\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0207\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0206\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_144 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 785us/step - loss: 0.0705\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0271\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0252\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0234\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0221\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0211\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0211\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_146 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0601\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0284\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0257\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0235\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0210\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0209\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0210\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0209\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0209\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0210\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0210\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0209\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0210\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0209\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0210\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0210\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0210\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0209\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0210\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0445\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0302\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0257\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0227\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0210\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0210\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 830us/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0210\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0211\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0595\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0288\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0256\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0233\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0210\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0210\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0209\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0209\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 830us/step - loss: 0.0209\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0210\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0209\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0209\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0209\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0210\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0210\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0210\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0210\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0209\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0210\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_152 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0952\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0262\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0251\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0242\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0233\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0225\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0207\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0205\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0205\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0205\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0204\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0205\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0205\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0204\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0205\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0205\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0205\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0205\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0205\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0205\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0205\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0205\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0205\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0204\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0205\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0204\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0205\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0205\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 738us/step - loss: 0.0204\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 702us/step - loss: 0.0205\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0205\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0205\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0204\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0205\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0205\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0205\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0204\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0205\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0205\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0204\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0204\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0205\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0205\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_154 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0701\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0255\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0242\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0230\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0222\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 693us/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0210\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0209\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0209\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0209\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0209\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0208\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0209\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0209\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0209\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0209\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0209\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0209\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0209\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0209\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0210\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0209\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0209\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0209\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0209\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0209\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 826us/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0209\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0209\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0209\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0209\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0209\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0209\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0209\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0209\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_156 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.1162\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0238\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0210\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0190\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0178\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0171\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0166\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0165\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0165\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0165\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0165\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0164\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_158 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 709us/step - loss: 0.0443\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0175\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 706us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 725us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 737us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 724us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0163\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0261\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0195\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0172\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 739us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 736us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0164\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0164\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0164\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_162 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.1475\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0277\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0245\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0197\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0182\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0172\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0161\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_164 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0697\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0164\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 724us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0161\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_166 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0947\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0248\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0221\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0201\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0175\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0170\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0169\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0168\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0167\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0165\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0165\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0165\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0165\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0165\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0165\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0164\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0164\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0164\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_168 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 714us/step - loss: 0.0411\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0182\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 716us/step - loss: 0.0163\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0421\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0241\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0207\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0185\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0174\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0162\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_172 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0235\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0170\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0160\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_174 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 687us/step - loss: 0.2971\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 730us/step - loss: 0.0427\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0349\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0312\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 726us/step - loss: 0.0280\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0252\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.0230\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0195\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0175\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 719us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0161\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_176 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.0278\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0194\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0161\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_178 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0297\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0190\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0172\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 720us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 718us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0162\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0681\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0194\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0188\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0182\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0178\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0174\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0171\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 709us/step - loss: 0.0168\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0167\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 667us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0163\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_182 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0961\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0200\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0176\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0159\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_184 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0729\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0257\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0208\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0186\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0174\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0158\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_186 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0861\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0249\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0221\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0201\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 698us/step - loss: 0.0186\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0177\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 716us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0159\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_188 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.3066\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 710us/step - loss: 0.0228\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0205\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0198\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0192\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0187\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0183\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0171\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 738us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 712us/step - loss: 0.0883\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0276\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0249\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0228\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0198\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0186\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0176\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0170\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 705us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 704us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 704us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 738us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 709us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 730us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_192 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0545\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0277\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0183\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0170\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0158\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_194 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0846\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 736us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 703us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0158\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_196 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0682\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0206\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0171\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0160\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_198 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0349\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0226\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0196\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0178\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0277\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0195\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0158\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_202 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.2182\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0310\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0279\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0252\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0230\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_204 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0602\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0212\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0199\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0188\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0180\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0173\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_206 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0491\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0222\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0201\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0186\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0176\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0170\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0159\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_208 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0773\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0204\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0192\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0182\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0175\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0171\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0168\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0166\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 719us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.2152\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0262\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0244\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 712us/step - loss: 0.0229\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0189\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0183\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 720us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0161\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_212 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0251\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 720us/step - loss: 0.0183\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 726us/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 736us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 830us/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0158\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_214 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0243\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0196\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0179\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 724us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 720us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0157\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_216 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0340\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0159\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_218 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0270\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0197\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.1674\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0276\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0252\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0232\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0202\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0191\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0183\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0173\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0170\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0166\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_222 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 847us/step - loss: 0.1321\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0346\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0282\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0189\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_224 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0601\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0195\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0182\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0172\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0157\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_226 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2108\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0337\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0309\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0283\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0259\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0240\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0223\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0199\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_228 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0282\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0208\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_230 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0451\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0269\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0209\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0184\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0172\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_232 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0424\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0204\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0182\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0156\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_234 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0551\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0260\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0229\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0208\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0193\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0182\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0174\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0168\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0158\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_236 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0190\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0178\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0158\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_238 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.2326\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0314\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0282\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0254\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0231\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.1267\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0241\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0199\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0189\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0182\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0176\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0171\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0167\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0158\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_242 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.3225\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0324\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0289\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0261\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0238\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0221\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0178\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0157\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_244 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0418\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0225\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0204\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0189\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0172\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+---------------------+----------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv        |        r2_bar        |        AIC         |        BIC         |\n",
      "+--------------+---------------------+----------------------+--------------------+--------------------+\n",
      "|     1.0      | 0.03174344359052359 | 0.03174344359052359  |   -3779.41015625   |   -3779.41015625   |\n",
      "|     2.0      | 0.04008879418375651 | 0.039892733888450785 |   -3785.83984375   |   -3785.83984375   |\n",
      "|     3.0      |  0.2548539509783435 |  0.2545494990686309  | -4032.13330078125  | -4032.13330078125  |\n",
      "|     4.0      |  0.2573547659986142 |  0.2568995278085847  | -4033.44873046875  | -4033.44873046875  |\n",
      "|     5.0      |  0.2613592505409793 | 0.26075541587965984  |  -4036.630859375   |  -4036.630859375   |\n",
      "|     6.0      | 0.27024934675848494 |  0.2695034855021056  | -4046.587158203125 | -4046.587158203125 |\n",
      "|     7.0      | 0.27252787705805026 | 0.27163545572546977  | -4047.67333984375  | -4047.67333984375  |\n",
      "|     8.0      | 0.27166173272540417 |  0.2706191217088556  | -4044.54931640625  | -4044.54931640625  |\n",
      "|     9.0      |  0.271250358007268  | 0.27005788569474154  |  -4041.927734375   |  -4041.927734375   |\n",
      "|     10.0     |  0.269503222000174  | 0.26815819929109097  | -4037.647216796875 | -4037.647216796875 |\n",
      "|     11.0     | 0.27077120326327614 |  0.2692790223818832  | -4037.33544921875  | -4037.33544921875  |\n",
      "+--------------+---------------------+----------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 2 values in the list are neurons of first 2 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_246 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0459\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0221\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0188\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0177\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0171\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 826us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0152\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_248 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0256\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0153\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0152\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0151\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0149\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0148\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0148\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0147\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0146\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0147\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0145\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0145\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0144\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0145\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0143\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0142\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0143\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0143\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0141\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0143\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0141\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0141\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0141\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0140\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_250 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0703\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0222\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0152\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0151\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0149\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0147\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0148\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0146\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0146\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0145\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0147\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_252 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0661\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0150\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0149\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0148\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0147\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0147\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0147\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0146\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_254 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0213\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0190\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0151\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0150\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0150\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0150\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0149\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0150\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0149\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+--------------------+--------------------+------------+------------+\n",
      "|       r2_cv        |       r2_bar       |    AIC     |    BIC     |\n",
      "+--------------------+--------------------+------------+------------+\n",
      "| 0.3124933179050061 | 0.3110865106979364 | -4095.1335 | -4095.1335 |\n",
      "+--------------------+--------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11)                132       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Fri, 01 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        23:55:25   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 11)                22        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 23:55:25.561792: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-01 23:55:25.561864: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-01 23:55:25.561905: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (localhost): /proc/driver/nvidia/version does not exist\n",
      "2022-04-01 23:55:25.562574: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 864us/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.2511\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 11)                22        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.1058\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0333\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0282\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0259\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0229\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0221\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0216\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0213\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0212\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0212\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 11)                22        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.1269\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0345\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0268\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0260\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0253\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0246\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0240\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0235\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0230\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0225\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0222\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0219\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0217\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0215\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0214\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0211\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 11)                22        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0752\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0301\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0270\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0246\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0229\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0208\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0207\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0207\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0206\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0206\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0206\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0206\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0207\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0207\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0206\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0206\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0206\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0207\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0207\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0206\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0206\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0207\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0206\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 726us/step - loss: 0.0207\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0206\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0206\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0206\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0206\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0206\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0207\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 830us/step - loss: 0.0206\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0206\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0207\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.0206\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0206\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0207\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0207\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0206\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0207\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0206\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0207\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0206\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0206\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0206\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.2529\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 711us/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.2511\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0777\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0314\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0284\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0261\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0242\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0229\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0221\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0216\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0213\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0212\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0210\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0210\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0210\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0210\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0210\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0210\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0210\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 738us/step - loss: 0.0210\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0209\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 714us/step - loss: 0.0209\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0209\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0209\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0209\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0209\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0208\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 738us/step - loss: 0.0208\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0208\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0209\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0208\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0208\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0208\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0208\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0208\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0207\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0207\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0207\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 674us/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.2528\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0740\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0322\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0288\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0258\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.0235\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0217\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0206\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0205\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0205\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0205\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0205\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0205\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0205\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0205\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0205\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0205\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0205\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0205\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0205\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0204\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0204\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0205\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0205\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0205\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0205\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0206\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0205\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0205\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0205\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0205\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0205\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0205\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0205\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0205\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0205\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0205\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0205\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0205\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0205\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0205\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0205\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0205\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0204\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0205\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0205\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0204\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0205\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0736\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0287\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0248\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0224\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0209\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0209\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0209\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0209\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0209\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0209\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0209\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0209\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0209\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0209\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0209\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0209\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0209\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0209\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0209\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0209\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0210\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0209\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0209\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0209\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0209\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0209\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0209\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0209\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0209\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0208\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0209\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0656\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0179\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0176\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0174\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0172\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0170\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0169\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0168\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0166\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 713us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0159\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.1124\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0227\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0179\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0176\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0173\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0170\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0167\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0162\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 737us/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 730us/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 781us/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 736us/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2528\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0890\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0244\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0208\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0184\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0170\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0160\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56\n",
      "Trainable params: 56\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 689us/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 699us/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 737us/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 712us/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 720us/step - loss: 0.2529\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0349\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 706us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0158\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.2519\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0737\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0251\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0192\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0180\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0172\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 720us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0157\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.2505\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.2505\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.2505\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.2505\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.2505\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.2505\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.2505\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.2505\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.2505\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.2505\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.2505\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.2505\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.2505\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.2505\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.2505\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.2505\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.2505\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.2505\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.2505\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.2505\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.2505\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.2505\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.2505\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.2505\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.2505\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.2505\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.2505\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.2505\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.2505\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.2505\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 718us/step - loss: 0.2505\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.2505\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.2505\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.2505\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 729us/step - loss: 0.2505\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2505\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.2505\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.2505\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 725us/step - loss: 0.2505\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.2505\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.2505\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.2505\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.2505\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.2505\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.2505\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.2505\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.2505\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.2505\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.2505\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0262\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0203\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0180\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 723us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 779us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0273\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 763us/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0156\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0156\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 736us/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0156\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0155\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0154\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 718us/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0154\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0154\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 742us/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0154\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0154\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 777us/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 733us/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.2519\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0763\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0201\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0191\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0183\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0176\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0172\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0169\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0167\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 744us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 765us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 736us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 715us/step - loss: 0.0158\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0874\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 770us/step - loss: 0.0210\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0173\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 774us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 707us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 726us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 729us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0156\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 718us/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 713us/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0154\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 745us/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0153\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0153\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 748us/step - loss: 0.0596\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 719us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 717us/step - loss: 0.0191\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 724us/step - loss: 0.0179\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0173\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 756us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 716us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 711us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 788us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 716us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 705us/step - loss: 0.0156\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 722us/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0155\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0155\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 772us/step - loss: 0.2040\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0192\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0170\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 740us/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0154\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0153\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0154\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 793us/step - loss: 0.0233\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0173\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0156\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0156\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0155\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0155\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0155\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0155\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0992\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0228\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0207\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0191\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0180\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0174\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0169\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0168\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0166\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0159\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0811\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0255\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0241\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0228\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0192\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0175\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 726us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 746us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 683us/step - loss: 0.0158\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 11)                77        \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 761us/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 721us/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 754us/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 694us/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2529\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_62 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0235\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0194\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0181\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0174\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 752us/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0154\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0148\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0148\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0147\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0146\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0146\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0145\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0145\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0145\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0143\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0704\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 784us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0152\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0152\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.1877\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0257\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0224\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0200\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0167\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0156\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0154\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0234\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0187\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 797us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0154\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0147\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0147\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0145\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 11)                88        \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100\n",
      "Trainable params: 100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0231\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0147\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0305\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0211\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0182\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 716us/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 836us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 755us/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0155\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 731us/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 712us/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0152\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0152\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 725us/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0152\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_74 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0353\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0197\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0182\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 751us/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 706us/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 743us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0156\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0149\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0149\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0610\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0173\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0152\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 710us/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0151\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0151\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0150\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0149\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 734us/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0149\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0149\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0949\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 758us/step - loss: 0.0252\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0194\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0176\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 757us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0156\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 749us/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 747us/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 768us/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 729us/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 718us/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0152\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0152\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0152\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0151\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0150\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 11)                99        \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.1017\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0270\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0232\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0208\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0193\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0177\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0173\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0169\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 826us/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 750us/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 723us/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 700us/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 700us/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 715us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 741us/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 728us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0156\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 674us/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 697us/step - loss: 0.0155\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0155\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 732us/step - loss: 0.0154\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0154\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0154\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0153\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0153\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0153\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_82 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0517\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0205\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0191\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0182\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0177\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0156\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0154\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0153\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0152\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 783us/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0148\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0492\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0230\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0199\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 735us/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 826us/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0149\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0148\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 767us/step - loss: 0.0148\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0147\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_86 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0968\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0287\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 766us/step - loss: 0.0185\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 771us/step - loss: 0.0173\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 753us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0152\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0153\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0149\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1047\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0180\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0153\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0148\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0146\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 769us/step - loss: 0.0145\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0145\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0145\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0144\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 11)                110       \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1563\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0261\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0173\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0156\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0154\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0149\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_92 (Dense)            (None, 11)                121       \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0520\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0189\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0184\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0179\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0174\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0169\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0153\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0152\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 801us/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 798us/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0149\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 11)                121       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0423\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0224\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0202\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0186\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0176\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 813us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0152\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0152\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 782us/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0150\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0148\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0148\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 11)                121       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0759\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0173\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 796us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 820us/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 760us/step - loss: 0.0153\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0153\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0152\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 792us/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0150\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0150\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_98 (Dense)            (None, 11)                121       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2505\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.2505\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.2505\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.2505\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.2505\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.2505\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.2505\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.2505\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 787us/step - loss: 0.2505\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.2505\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.2505\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.2505\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.2505\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.2505\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.2505\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.2505\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.2505\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.2505\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.2505\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.2505\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.2505\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.2505\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.2505\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2505\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.2505\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.2505\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.2505\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.2505\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.2505\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.2505\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2045\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 773us/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 806us/step - loss: 0.0149\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0148\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0148\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0148\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0148\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0148\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0147\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0147\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0147\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 814us/step - loss: 0.0146\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0146\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_102 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 785us/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 775us/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 780us/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 831us/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.2511\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0753\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0196\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0180\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 803us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 808us/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 727us/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 772us/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0151\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 791us/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0146\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 805us/step - loss: 0.0147\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0145\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 762us/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0144\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0916\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0197\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0177\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0172\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0152\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0152\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0151\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.0149\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0334\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 786us/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0156\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0154\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0154\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0151\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144\n",
      "Trainable params: 144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0665\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0247\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0178\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 759us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 800us/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0153\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0148\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0147\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0147\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 794us/step - loss: 0.0146\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 764us/step - loss: 0.0146\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 776us/step - loss: 0.0146\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv        |        r2_bar       |        AIC         |        BIC         |\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n",
      "|     1.0      |  -4.252721526090421 |  -4.252721526090421 | -2806.016845703125 | -2806.016845703125 |\n",
      "|     2.0      |  -4.274945630055926 | -4.2760230290816725 | -2807.95068359375  | -2807.95068359375  |\n",
      "|     3.0      | -4.0194092153549805 |  -4.021460046495065 | -2970.11962890625  | -2970.11962890625  |\n",
      "|     4.0      |  -4.037255645098797 |  -4.040343460165266 | -2973.43115234375  | -2973.43115234375  |\n",
      "|     5.0      | -1.9635243444262573 | -1.9659470089220068 | -3513.06201171875  | -3513.06201171875  |\n",
      "|     6.0      |  -1.844839534845573 | -1.8477471795050633 | -3527.405029296875 | -3527.405029296875 |\n",
      "|     7.0      |  0.3107940193991543 | 0.30994854078872597 | -4100.84912109375  | -4100.84912109375  |\n",
      "|     8.0      |  0.2952606379103958 | 0.29425180855771127 | -4076.878173828125 | -4076.878173828125 |\n",
      "|     9.0      | 0.30873738164078607 |  0.3076062503364552 | -4093.77587890625  | -4093.77587890625  |\n",
      "|     10.0     | -1.7718896954134902 | -1.7769934203027535 | -3539.949951171875 | -3539.949951171875 |\n",
      "|     11.0     | -1.9467344446865862 | -1.9527641857233906 |   -3538.11328125   |   -3538.11328125   |\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case, the first 3 values in the list are neurons of first 3 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The middle value is the hidden layers\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 2 * X.shape[1] + 1, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0227\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0202\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_115 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0196\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0190\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0184\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0171\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0268\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0207\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0191\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0186\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0217\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0179\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0174\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0171\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0168\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0157\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+--------------------+--------------------+------------+------------+\n",
      "|       r2_cv        |       r2_bar       |    AIC     |    BIC     |\n",
      "+--------------------+--------------------+------------+------------+\n",
      "| 0.2681812480352283 | 0.2666837674705368 | -4033.7253 | -4033.7253 |\n",
      "+--------------------+--------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Sat, 02 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        00:04:39   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0372\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0218\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0219\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0219\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0218\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0218\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0218\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0217\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0217\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0217\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0216\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0215\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0214\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0215\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0214\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0214\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0213\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0211\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_133 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0236\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0218\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0218\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0217\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0217\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0217\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0217\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0216\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0215\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0215\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0215\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0215\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0393\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0218\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0218\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0218\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0217\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0217\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0218\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0217\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0216\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0215\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0212\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_139 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0851\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0213\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0213\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0212\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0210\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0210\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0209\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0209\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0208\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0208\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0208\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0207\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0207\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0208\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0207\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0207\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0207\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0207\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0207\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0207\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0206\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0206\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0206\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_142 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0218\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0218\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0218\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0218\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0217\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0217\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0216\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0216\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0215\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0216\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0215\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0214\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0214\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0213\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0218\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0217\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0216\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0216\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0216\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0215\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0214\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0214\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0215\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0210\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0210\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0209\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0209\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0209\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0209\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0209\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0210\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0224\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0217\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0217\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0216\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0216\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0215\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0215\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0214\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0214\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0215\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0210\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_151 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0218\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0218\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0217\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0216\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0216\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0215\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0215\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0214\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0213\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0214\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0214\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_154 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0216\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0208\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0208\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0207\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0207\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0207\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0207\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0205\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0205\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0205\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0205\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0205\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0205\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_157 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0440\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0216\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0215\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0209\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0379\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0202\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0197\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0193\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0188\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0183\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0179\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0176\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0172\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0167\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0166\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0163\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_163 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0433\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0208\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0205\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0201\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0185\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0181\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0178\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0175\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0172\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0171\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0170\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0164\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_166 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0400\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0192\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0184\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0180\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0171\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0170\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0168\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0163\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_169 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0325\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0206\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0204\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0197\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0188\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_172 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0207\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0202\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 809us/step - loss: 0.0197\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0190\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0161\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_175 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0185\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0178\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_178 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 853us/step - loss: 0.0276\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0191\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0186\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0178\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0165\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0162\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_181 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0195\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0190\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0175\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_184 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0211\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0209\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0207\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0196\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0186\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0177\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_187 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0193\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0160\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0243\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0161\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_193 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0234\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0205\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0193\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0162\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_196 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0218\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0205\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0195\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0189\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0184\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 804us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_199 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0216\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_202 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0284\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0192\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0181\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_205 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0192\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_208 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0264\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0221\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0208\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0200\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0195\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0190\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 807us/step - loss: 0.0185\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0175\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0173\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0172\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0167\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_211 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0268\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0174\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0169\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0161\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_214 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0360\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0212\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0205\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0200\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 789us/step - loss: 0.0197\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 824us/step - loss: 0.0193\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0189\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0185\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0181\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0178\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0175\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 850us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0159\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_217 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0229\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0195\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0189\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0183\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0253\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 818us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_223 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0234\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0188\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_226 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 980us/step - loss: 0.0259\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0159\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_229 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 925us/step - loss: 0.0224\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0205\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0175\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_232 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0292\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_235 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0227\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_238 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0256\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_241 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0225\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0195\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0178\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0175\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0159\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_244 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0214\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0208\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0199\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0193\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0188\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0181\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0157\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_247 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0225\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0205\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0194\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0188\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0183\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_250 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0195\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 852us/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_253 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0380\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0196\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0192\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0173\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0171\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0159\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_256 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_259 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0211\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0208\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0204\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0199\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0194\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0188\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0177\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0170\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0167\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0166\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_262 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0259\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_265 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_268 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0231\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0193\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_271 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0230\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0181\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0158\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_274 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0299\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0203\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 812us/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0193\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0187\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0177\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 810us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_277 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0684\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0208\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0205\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0199\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0194\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0187\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0184\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0180\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0174\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0158\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_280 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0230\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0197\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_283 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 956us/step - loss: 0.0224\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_286 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0230\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_289 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 974us/step - loss: 0.0215\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0207\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0167\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_292 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0487\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+----------------------+---------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv         |        r2_bar       |        AIC         |        BIC         |\n",
      "+--------------+----------------------+---------------------+--------------------+--------------------+\n",
      "|     1.0      | 0.03626831106929311  | 0.03626831106929311 | -3783.971435546875 | -3783.971435546875 |\n",
      "|     2.0      | 0.040072391509138064 | 0.03987632786361286 | -3785.840576171875 | -3785.840576171875 |\n",
      "|     3.0      |  0.2562443202120794  |  0.2559404363796839 | -4033.91552734375  | -4033.91552734375  |\n",
      "|     4.0      | 0.25626583275022863  |  0.255809927049013  | -4032.05029296875  | -4032.05029296875  |\n",
      "|     5.0      | 0.26257917470494074  |  0.2619763373247691 | -4038.326904296875 | -4038.326904296875 |\n",
      "|     6.0      |  0.2656605671312612  | 0.26491001578940837 |    -4040.40625     |    -4040.40625     |\n",
      "|     7.0      | 0.27124537073503435  | 0.27035137609680293 | -4045.858642578125 | -4045.858642578125 |\n",
      "|     8.0      |  0.2713408772390685  |  0.2702978069201878 |  -4044.044921875   |  -4044.044921875   |\n",
      "|     9.0      |  0.2700211781477705  |  0.2688266944957317 | -4040.22705078125  | -4040.22705078125  |\n",
      "|     10.0     |  0.2657043572697468  |  0.2643523399242942 |  -4032.501953125   |  -4032.501953125   |\n",
      "|     11.0     |  0.2663483363263882  |  0.2648471051750201 | -4031.31103515625  | -4031.31103515625  |\n",
      "+--------------+----------------------+---------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case, the first 3 values in the list are neurons of first 3 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The middle value is the hidden layers\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 2 * X.shape[1] + 1, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_295 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 910us/step - loss: 0.0705\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_298 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0432\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0181\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0174\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0170\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_301 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0564\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0183\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_304 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0208\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_307 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0279\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0191\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0179\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+---------------------+--------------------+----------+----------+\n",
      "|        r2_cv        |       r2_bar       |   AIC    |   BIC    |\n",
      "+---------------------+--------------------+----------+----------+\n",
      "| 0.25808864918762886 | 0.2565705166915938 | -4021.06 | -4021.06 |\n",
      "+---------------------+--------------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_310 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Sat, 02 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        00:15:05   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_313 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0642\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0211\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0213\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0212\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_316 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0408\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0244\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0213\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0213\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0213\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0213\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0214\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0213\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0213\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_319 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0442\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0237\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0213\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0214\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0212\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0213\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0213\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0213\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0213\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0213\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0213\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0213\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_322 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0486\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0242\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0208\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0208\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0207\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0207\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0207\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0207\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0207\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0207\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0207\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0207\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0207\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0207\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0207\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0207\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0208\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0207\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0207\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0208\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0208\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0208\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0207\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0207\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0207\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_325 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0506\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0230\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0214\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 821us/step - loss: 0.0211\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_328 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0484\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0210\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0210\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0210\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0210\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0212\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_331 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0586\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0213\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_334 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0440\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0244\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0210\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0210\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0210\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0210\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0211\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_337 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0503\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0228\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0206\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0205\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0206\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0206\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0205\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0206\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0207\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0206\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0206\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0206\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0205\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0206\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0205\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0206\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0205\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_340 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 994us/step - loss: 0.0494\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0243\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0210\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0209\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0209\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0209\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0209\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0209\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0209\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0209\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0209\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_343 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0606\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0165\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0165\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_346 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0376\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0165\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0165\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0165\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_349 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 981us/step - loss: 0.0272\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0178\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0165\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0165\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0164\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_352 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0272\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0161\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_355 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0485\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0187\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0161\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_358 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_360 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0206\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0165\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0164\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_361 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0586\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0165\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0165\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0165\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0167\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_364 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0265\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 819us/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0164\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_367 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0444\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0163\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_370 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0459\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0163\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0160\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_373 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.1172\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0192\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0178\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0172\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0167\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0167\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0167\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0166\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_376 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0305\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0166\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 802us/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_379 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_380 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0638\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_382 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0820\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0194\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0159\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_385 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0779\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_388 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_390 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 978us/step - loss: 0.0472\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0170\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0163\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_391 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 939us/step - loss: 0.0296\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0160\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_394 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 974us/step - loss: 0.0858\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0160\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_397 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0223\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0158\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_400 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 934us/step - loss: 0.0489\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 832us/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_403 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_406 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 887us/step - loss: 0.0284\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_409 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_410 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0521\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_412 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.1055\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_415 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0241\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0155\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0155\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_418 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_420 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0737\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0175\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 854us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 778us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_421 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0413\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0160\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_424 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_425 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0831\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0188\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0173\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 829us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0160\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_427 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0299\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 834us/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 828us/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 811us/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 833us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 844us/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0156\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_430 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0170\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 815us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0157\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_433 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_435 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0462\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0176\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0170\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_436 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0325\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0157\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_439 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_440 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0626\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0158\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_442 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0273\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_445 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0266\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0156\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_448 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_450 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 899us/step - loss: 0.0340\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_451 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0648\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_454 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_456 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0228\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_457 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_459 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0240\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_460 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_462 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 983us/step - loss: 0.0363\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0188\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0155\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0154\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_463 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0359\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_466 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_468 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0485\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0175\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 862us/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 823us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 837us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0160\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_469 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_470 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_471 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0316\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0170\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0155\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_472 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_473 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_474 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 935us/step - loss: 0.0262\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0156\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0156\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0152\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0154\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_475 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_476 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_477 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 870us/step - loss: 0.0437\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0156\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+----------------------+----------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv         |        r2_bar        |        AIC         |        BIC         |\n",
      "+--------------+----------------------+----------------------+--------------------+--------------------+\n",
      "|     1.0      | 0.03320416353499396  | 0.03320416353499396  | -3780.891845703125 | -3780.891845703125 |\n",
      "|     2.0      | 0.042633438620655426 | 0.042437898064818035 | -3788.452392578125 | -3788.452392578125 |\n",
      "|     3.0      | 0.25140290316590824  | 0.25109704122644577  | -4027.62939453125  | -4027.62939453125  |\n",
      "|     4.0      | 0.26104931610608517  | 0.26059634265866355  | -4038.274169921875 | -4038.274169921875 |\n",
      "|     5.0      |  0.2669354337116857  |  0.2663361575487687  | -4044.18798828125  | -4044.18798828125  |\n",
      "|     6.0      |  0.2677377398389014  | 0.26698931152720773  | -4043.352783203125 | -4043.352783203125 |\n",
      "|     7.0      | 0.27687473810446317  | 0.27598764925323166  | -4053.66259765625  | -4053.66259765625  |\n",
      "|     8.0      |  0.2717211570653625  |  0.2706786311143312  | -4044.55712890625  | -4044.55712890625  |\n",
      "|     9.0      |  0.2729088917719942  |  0.2717191333621304  | -4044.01318359375  | -4044.01318359375  |\n",
      "|     10.0     | 0.27033027126574904  |  0.2689867713560502  | -4038.479248046875 | -4038.479248046875 |\n",
      "|     11.0     | 0.28207603844312185  | 0.28060699002577605  | -4052.990966796875 | -4052.990966796875 |\n",
      "+--------------+----------------------+----------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case, the first 3 values in the list are neurons of first 3 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The middle value is the hidden layers\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 2 * X.shape[1] + 1, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_478 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_479 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_480 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 937us/step - loss: 0.0439\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0154\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0152\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0149\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0148\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_481 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_482 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_483 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 898us/step - loss: 0.0381\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0145\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0146\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0142\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0140\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0139\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0136\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_484 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_485 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_486 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0579\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0152\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0148\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0148\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0146\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0145\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_487 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_488 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_489 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0522\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0149\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0148\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0145\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0144\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0143\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0143\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0144\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0145\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0141\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0142\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0141\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0141\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0140\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0140\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0139\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_490 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_492 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.1168\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0161\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0158\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0152\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0151\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0149\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0149\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0149\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0149\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0148\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0148\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0145\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0144\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0143\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0142\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0141\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0142\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0142\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0140\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+---------------------+--------------------+------------+------------+\n",
      "|        r2_cv        |       r2_bar       |    AIC     |    BIC     |\n",
      "+---------------------+--------------------+------------+------------+\n",
      "| 0.32376097035773327 | 0.3223772195297361 | -4111.2383 | -4111.2383 |\n",
      "+---------------------+--------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_493 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_495 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Sat, 02 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        00:25:28   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_496 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_498 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 790us/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2511\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_499 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_500 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_501 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 999us/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.2519\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_502 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_504 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.2528\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_505 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_507 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.2505\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.2505\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.2505\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.2505\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.2505\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.2505\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.2505\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.2505\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.2505\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.2505\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2505\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.2505\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.2505\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2505\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.2505\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.2505\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.2505\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2505\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.2505\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.2505\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.2505\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2505\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.2505\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.2505\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.2505\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.2505\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.2505\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.2505\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.2505\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.2505\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_508 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_509 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_510 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2529\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_511 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_512 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_513 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2511\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_514 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_515 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_516 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 914us/step - loss: 0.0895\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0209\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0208\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0208\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0208\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0208\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0207\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0209\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0207\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0209\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0207\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0208\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0207\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0208\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0207\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0208\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0206\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0206\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0205\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0207\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0205\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_517 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_518 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_519 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 988us/step - loss: 0.0595\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0204\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0204\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0202\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0201\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0201\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0201\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0200\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0201\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0202\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0200\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_520 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_521 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_522 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0604\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0205\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0204\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0205\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0204\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0203\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0204\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0203\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0204\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0203\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0203\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0202\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0203\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0203\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0204\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0202\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0201\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0201\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0201\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0201\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0201\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0203\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0202\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0201\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0201\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0201\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_523 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_524 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_525 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.2529\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_526 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_527 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_528 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_529 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_530 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_531 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 960us/step - loss: 0.1898\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_532 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_533 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_534 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0423\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0160\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_535 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_536 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_537 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 917us/step - loss: 0.0281\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0165\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0156\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0155\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0155\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0155\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0152\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_538 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_539 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_540 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 995us/step - loss: 0.0618\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0153\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_541 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_542 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_543 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.2511\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_544 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_545 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.2519\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_547 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0423\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0161\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0156\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0156\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0156\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0156\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0155\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_550 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0571\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0153\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0152\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_553 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_554 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_555 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 355\n",
      "Trainable params: 355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0702\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0174\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 839us/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 842us/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_556 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_557 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_558 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0541\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 826us/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 857us/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0148\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0149\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0149\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_559 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_560 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_561 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 914us/step - loss: 0.0242\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0170\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 799us/step - loss: 0.0159\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_562 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_563 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_564 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 910us/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.2528\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_565 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_566 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_567 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0352\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0154\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0153\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0152\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0152\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0151\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_568 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_569 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_570 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366\n",
      "Trainable params: 366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.2529\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_571 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_572 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_573 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 849us/step - loss: 0.0779\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0194\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0181\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0173\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 822us/step - loss: 0.0168\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 853us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0152\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_574 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_575 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_576 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0939\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0166\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_577 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_578 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_579 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_580 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_581 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_582 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 997us/step - loss: 0.0443\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0180\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 856us/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 885us/step - loss: 0.0147\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0146\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_583 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_584 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_585 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 892us/step - loss: 0.0253\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0195\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0153\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_586 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_587 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_588 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 916us/step - loss: 0.0253\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 817us/step - loss: 0.0175\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0143\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0143\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0143\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_589 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_590 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_591 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0306\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 884us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0147\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0148\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0143\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0142\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0143\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_592 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_593 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_594 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 849us/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 913us/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 899us/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 873us/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 843us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.2528\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_595 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_596 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_597 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0432\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0189\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0172\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0154\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0141\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0141\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_598 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_599 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_600 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388\n",
      "Trainable params: 388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_601 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_602 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_603 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0592\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0175\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 871us/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0152\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0152\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 827us/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0149\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0149\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0148\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0144\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_604 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_605 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_606 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0508\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0156\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 795us/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0154\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 863us/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0150\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0148\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_607 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_608 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_609 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 883us/step - loss: 0.0252\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0148\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0148\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0148\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0146\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 846us/step - loss: 0.0145\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0147\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0147\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0144\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0145\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 865us/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0144\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_610 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_611 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_612 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 872us/step - loss: 0.0365\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0148\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 888us/step - loss: 0.0147\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0147\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0145\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0144\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0144\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0141\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0142\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0140\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0141\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0140\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0139\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0140\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0140\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0138\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0139\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 840us/step - loss: 0.0139\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_613 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_614 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_615 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 399\n",
      "Trainable params: 399\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0336\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0192\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 855us/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0148\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0147\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0143\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0143\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0142\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_616 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_617 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_618 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2000\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0183\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0150\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0146\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0141\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0141\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_619 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_620 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_621 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0352\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0149\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0148\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0147\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0147\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0146\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0148\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 868us/step - loss: 0.0146\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0145\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0144\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 870us/step - loss: 0.0145\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0144\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0142\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0142\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0141\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0142\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0141\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0141\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0139\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 880us/step - loss: 0.0139\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0139\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0140\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_622 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_624 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 842us/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_625 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_627 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0664\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0145\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0145\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0144\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0144\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0142\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0142\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0142\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0141\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0141\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 898us/step - loss: 0.0140\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0139\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0139\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_628 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_630 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410\n",
      "Trainable params: 410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0524\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0157\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0146\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0145\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0144\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0144\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0144\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0143\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0143\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_631 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_633 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 2s 1ms/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.2511\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_634 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_636 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 926us/step - loss: 0.0358\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 882us/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0149\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_637 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_639 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0421\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0172\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0155\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0153\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0152\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0149\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0148\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0144\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0140\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_640 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_641 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_642 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0555\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0143\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_643 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_644 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_645 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0301\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0180\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0154\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0152\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0150\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0149\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0144\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0143\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_646 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_647 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_648 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 923us/step - loss: 0.0280\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0185\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0143\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0142\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0144\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0141\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0139\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0139\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0140\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0140\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0138\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0137\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0137\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0136\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0136\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0139\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0136\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0136\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0135\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0135\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0135\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_649 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_650 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_651 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_652 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_654 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 963us/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_655 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_656 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_657 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0415\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0141\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0139\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0138\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0134\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0133\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0133\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0133\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0132\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 835us/step - loss: 0.0136\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0133\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 866us/step - loss: 0.0132\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0132\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0133\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0132\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0131\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_658 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_659 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_660 (Dense)           (None, 1)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0350\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0144\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0142\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0139\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+---------------------+---------------------+---------------------+---------------------+\n",
      "| Num_Features |        r2_cv        |        r2_bar       |         AIC         |         BIC         |\n",
      "+--------------+---------------------+---------------------+---------------------+---------------------+\n",
      "|     1.0      |  -10.57954642295093 |  -10.57954642295093 | -1348.9036865234375 | -1348.9036865234375 |\n",
      "|     2.0      |  -4.22887296387169  |  -4.229940952630651 |  -2828.82080078125  |  -2828.82080078125  |\n",
      "|     3.0      | -1.9749359745380068 | -1.9761514744254587 |    -3514.65234375   |    -3514.65234375   |\n",
      "|     4.0      |  -4.225532805417747 |  -4.228736033537129 |  -2954.40966796875  |  -2954.40966796875  |\n",
      "|     5.0      |  -4.00114739653515  | -4.0052358064239995 |  -2990.94580078125  |  -2990.94580078125  |\n",
      "|     6.0      |  -1.87257253067517  |  -1.875508520587961 |  -3526.165283203125 |  -3526.165283203125 |\n",
      "|     7.0      | -3.9825638834250703 |  -3.988676208777872 |   -3013.841796875   |   -3013.841796875   |\n",
      "|     8.0      |  0.3221591643237171 |  0.321188840019068  |    -4115.51953125   |    -4115.51953125   |\n",
      "|     9.0      | -1.8294196076796936 | -1.8340494618137577 |  -3582.07275390625  |  -3582.07275390625  |\n",
      "|     10.0     | -1.9247375841674625 | -1.9301227392937936 |    -3571.87890625   |    -3571.87890625   |\n",
      "|     11.0     |  -4.082703409319497 |  -4.09310386646973  |  -3015.82763671875  |  -3015.82763671875  |\n",
      "+--------------+---------------------+---------------------+---------------------+---------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case, the first 4 values in the list are neurons of first 4 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The middle values are hidden layers\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 2 * X.shape[1] + 1, math.ceil((2 * X.shape[1] + 1)/2), 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_661 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_662 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_663 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_664 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0225\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_665 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_666 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_667 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_668 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0228\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_669 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_670 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_671 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_672 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0237\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_673 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_674 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_675 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_676 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0216\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0157\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_677 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_678 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_680 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 966us/step - loss: 0.0218\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+--------------------+--------------------+------------+------------+\n",
      "|       r2_cv        |       r2_bar       |    AIC     |    BIC     |\n",
      "+--------------------+--------------------+------------+------------+\n",
      "| 0.2655744550829483 | 0.2640716403808468 | -4030.2969 | -4030.2969 |\n",
      "+--------------------+--------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 11)                132       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 23)                276       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12)                288       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Sat, 02 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        01:31:25   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 11)                22        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 23)                276       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 12)                288       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0275\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0220\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0215\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0214\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0236\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0220\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0220\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0217\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0216\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0214\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0214\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0213\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0212\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0248\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0219\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0219\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0218\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0218\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0215\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0214\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0213\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0213\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0213\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0211\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0215\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0214\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0214\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0213\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0208\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0208\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0207\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0207\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0206\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0206\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0218\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0218\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0218\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0217\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0216\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 952us/step - loss: 0.0216\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0216\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0216\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0214\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0260\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0219\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0219\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0219\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0219\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0219\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0219\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0218\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0218\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0217\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0220\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0220\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0219\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0219\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0218\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0218\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0216\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0216\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0216\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0214\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0215\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 907us/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0218\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0218\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0218\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0218\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0218\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0216\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0214\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 860us/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0210\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0210\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0208\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0206\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0206\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0205\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0205\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0205\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0205\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0205\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0205\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 883us/step - loss: 0.0205\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0205\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0205\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0205\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0205\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0218\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0218\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0217\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0217\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0217\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 896us/step - loss: 0.0216\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0217\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0216\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0215\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0213\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0209\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0226\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 889us/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0164\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0355\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0216\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0211\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0166\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0223\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0204\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 891us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_62 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0226\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0217\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0183\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0177\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0164\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0246\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0168\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_74 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0177\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 909us/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0163\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0346\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0193\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0181\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_82 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0218\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 845us/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 914us/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 905us/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_86 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0237\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0218\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0210\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0197\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0188\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0181\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 893us/step - loss: 0.0168\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0167\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0165\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 922us/step - loss: 0.0214\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0189\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 927us/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 851us/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0322\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 872us/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 816us/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0172\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0171\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0168\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_98 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 940us/step - loss: 0.0234\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0192\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_102 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 848us/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 890us/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 878us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 825us/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 912us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0221\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 847us/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 932us/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0363\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0205\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0195\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0172\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0167\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0166\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_114 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 942us/step - loss: 0.0241\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0187\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 937us/step - loss: 0.0179\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 887us/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 967us/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 988us/step - loss: 0.0167\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 949us/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 946us/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 911us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 876us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_122 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 917us/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0209\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_126 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 981us/step - loss: 0.0189\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 994us/step - loss: 0.0177\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 951us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0224\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0194\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0178\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0172\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_134 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0255\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0181\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_138 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0305\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 902us/step - loss: 0.0197\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 989us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_142 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0279\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 948us/step - loss: 0.0204\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 931us/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_146 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 999us/step - loss: 0.0233\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0194\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 892us/step - loss: 0.0173\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0170\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 992us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 975us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0249\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 864us/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 900us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 841us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 910us/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 904us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_154 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0402\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 926us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 861us/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 874us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 869us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 886us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 968us/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 915us/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_158 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0217\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0184\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 921us/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 938us/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 875us/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 867us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 928us/step - loss: 0.0158\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_162 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 918us/step - loss: 0.0245\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 998us/step - loss: 0.0203\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 881us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 969us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 920us/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 999us/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 982us/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 858us/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 976us/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 936us/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 935us/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_166 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0231\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0197\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 903us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 953us/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 979us/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 958us/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 925us/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0225\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0199\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_174 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0241\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_178 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0509\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1000us/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0186\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 944us/step - loss: 0.0180\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 924us/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 983us/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 974us/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_182 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0230\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0196\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0174\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 985us/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_186 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0251\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0187\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 945us/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 859us/step - loss: 0.0174\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 930us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 897us/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 955us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0220\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 941us/step - loss: 0.0218\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0180\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 990us/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 916us/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 877us/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_194 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 933us/step - loss: 0.0207\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 906us/step - loss: 0.0201\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0192\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0183\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 939us/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 901us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 987us/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_198 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0244\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0190\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 962us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 970us/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_202 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0246\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0216\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 978us/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_206 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0199\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0181\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 956us/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 973us/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 879us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0184\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 895us/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 977us/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 957us/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 980us/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_214 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0222\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 942us/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_218 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0218\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0199\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0182\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0175\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_222 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0219\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 993us/step - loss: 0.0200\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 963us/step - loss: 0.0182\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 919us/step - loss: 0.0176\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 984us/step - loss: 0.0172\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 838us/step - loss: 0.0170\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 943us/step - loss: 0.0167\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 986us/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 894us/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 947us/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 964us/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 908us/step - loss: 0.0158\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+---------------------+----------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv        |        r2_bar        |        AIC         |        BIC         |\n",
      "+--------------+---------------------+----------------------+--------------------+--------------------+\n",
      "|     1.0      | 0.03575144890451376 | 0.03575144890451376  | -3783.461669921875 | -3783.461669921875 |\n",
      "|     2.0      | 0.04398834733470549 | 0.043793083516759035 | -3789.838623046875 | -3789.838623046875 |\n",
      "|     3.0      |  0.2564025436477016 | 0.25609872446226645  | -4034.119873046875 | -4034.119873046875 |\n",
      "|     4.0      | 0.25907288830960623 |   0.25861870332083   |   -4035.62890625   |   -4035.62890625   |\n",
      "|     5.0      |  0.2578295452076504 | 0.25722282503205884  | -4032.016357421875 | -4032.016357421875 |\n",
      "|     6.0      | 0.26017034687937557 | 0.25941418411044603  | -4033.110107421875 | -4033.110107421875 |\n",
      "|     7.0      | 0.26575801849038827 |  0.2648572922812168  | -4038.577392578125 | -4038.577392578125 |\n",
      "|     8.0      | 0.26781294328407784 |  0.2667648227529916  | -4039.20361328125  | -4039.20361328125  |\n",
      "|     9.0      |  0.2667647829258234 | 0.26556497074816054  |  -4035.861328125   |  -4035.861328125   |\n",
      "|     10.0     |  0.2674268545415435 | 0.26607800873362086  |  -4034.779296875   |  -4034.779296875   |\n",
      "|     11.0     |  0.2681059163634691 |  0.2666082816517104  | -4033.62939453125  | -4033.62939453125  |\n",
      "+--------------+---------------------+----------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case, the first 4 values in the list are neurons of first 4 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The middle values are hidden layers\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 2 * X.shape[1] + 1, math.ceil((2 * X.shape[1] + 1)/2), 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_226 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0309\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 923us/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 959us/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 991us/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_230 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0241\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 950us/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_234 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 959us/step - loss: 0.0354\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 954us/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 997us/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_238 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0254\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 934us/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 996us/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 972us/step - loss: 0.0149\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 960us/step - loss: 0.0148\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 965us/step - loss: 0.0148\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_242 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0818\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 971us/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 961us/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 929us/step - loss: 0.0153\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 966us/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 995us/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+---------------------+---------------------+-----------+-----------+\n",
      "|        r2_cv        |        r2_bar       |    AIC    |    BIC    |\n",
      "+---------------------+---------------------+-----------+-----------+\n",
      "| 0.31317858455637376 | 0.31177317957285916 | -4096.298 | -4096.298 |\n",
      "+---------------------+---------------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11)                132       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 23)                276       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                288       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Sat, 02 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:18:46   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 11)                22        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 23)                276       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 12)                288       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0357\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0216\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 11)                22        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 23)                276       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0451\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0217\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0216\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0215\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0464\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0337\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 11)                22        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0362\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0217\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0414\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0226\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0328\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0216\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0470\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0228\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0384\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0215\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 11)                33        \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0428\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0250\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0442\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0293\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0226\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 11)                44        \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0319\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0355\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0486\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0389\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0268\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 11)                55        \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0547\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0257\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0216\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_92 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0489\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 23)                276       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 12)                288       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0193\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0296\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0186\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0253\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0354\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_116 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0252\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0372\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0524\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_128 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0174\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_132 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0536\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0454\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0276\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_144 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0263\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0197\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_152 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0424\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_156 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0582\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0315\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_164 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0605\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_168 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0185\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_172 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0275\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_176 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0624\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0433\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_184 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0345\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_188 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0661\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_192 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0767\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_196 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0227\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_200 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0327\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0184\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_204 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0373\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_208 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0191\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_212 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0214\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_216 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0312\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0338\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0180\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+----------------------+----------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv         |        r2_bar        |        AIC         |        BIC         |\n",
      "+--------------+----------------------+----------------------+--------------------+--------------------+\n",
      "|     1.0      | 0.028697455509687542 | 0.028697455509687542 | -3776.324951171875 | -3776.324951171875 |\n",
      "|     2.0      | 0.03890912985501811  | 0.038712828615200826 | -3784.637451171875 | -3784.637451171875 |\n",
      "|     3.0      |  0.2550356808996307  |  0.2547313032411626  | -4032.311279296875 | -4032.311279296875 |\n",
      "|     4.0      | 0.26162402182988315  | 0.26117140067448663  | -4039.167236328125 | -4039.167236328125 |\n",
      "|     5.0      | 0.26181492513756793  |  0.2612114629876702  | -4037.190673828125 | -4037.190673828125 |\n",
      "|     6.0      | 0.27638463678183195  | 0.27564504626341607  | -4054.987548828125 | -4054.987548828125 |\n",
      "|     7.0      |  0.2952551500209516  | 0.29439060921132687  | -4078.77197265625  | -4078.77197265625  |\n",
      "|     8.0      |  0.2921597537118939  |  0.2911464854656737  |  -4073.544921875   |  -4073.544921875   |\n",
      "|     9.0      |  0.2932659406264774  |  0.2921094929940396  | -4071.795654296875 | -4071.795654296875 |\n",
      "|     10.0     | 0.31159110927584494  | 0.31032358063089466  | -4095.74951171875  | -4095.74951171875  |\n",
      "|     11.0     | 0.30753494748084165  |  0.3061179942323883  | -4088.116455078125 | -4088.116455078125 |\n",
      "+--------------+----------------------+----------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spenc\\Desktop\\UGA_projects\\data_science\\DS2_P2\\python\\Model_Parent_2.py:318: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case, the first 4 values in the list are neurons of first 4 layers.\n",
    "# The first value corresponds to the input layer\n",
    "# The middle values are hidden layers\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [X.shape[1], 2 * X.shape[1] + 1, math.ceil((2 * X.shape[1] + 1)/2), 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_224 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0500\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_228 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_232 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0387\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_236 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0880\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0500\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0165\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "+---------------------+---------------------+-----------+-----------+\n",
      "|        r2_cv        |        r2_bar       |    AIC    |    BIC    |\n",
      "+---------------------+---------------------+-----------+-----------+\n",
      "| -1.9199158013023072 | -1.9258906648204213 | -3562.733 | -3562.733 |\n",
      "+---------------------+---------------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_244 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "FORWARD SELECTION REPORT:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.282\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     174.3\n",
      "Date:                Sat, 02 Apr 2022   Prob (F-statistic):               0.00\n",
      "Time:                        10:35:16   Log-Likelihood:                 3232.3\n",
      "No. Observations:                4898   AIC:                            -6441.\n",
      "Df Residuals:                    4886   BIC:                            -6363.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.4251      0.018     23.735      0.000       0.390       0.460\n",
      "fixed acidity            0.1136      0.036      3.139      0.002       0.043       0.184\n",
      "volatile acidity        -0.3167      0.019    -16.373      0.000      -0.355      -0.279\n",
      "citric acid              0.0061      0.026      0.231      0.818      -0.046       0.058\n",
      "residual sugar           0.8854      0.082     10.825      0.000       0.725       1.046\n",
      "chlorides               -0.0139      0.031     -0.452      0.651      -0.074       0.046\n",
      "free sulfur dioxide      0.1786      0.040      4.422      0.000       0.099       0.258\n",
      "total sulfur dioxide    -0.0205      0.027     -0.756      0.450      -0.074       0.033\n",
      "density                 -1.2992      0.165     -7.879      0.000      -1.622      -0.976\n",
      "pH                       0.1258      0.019      6.513      0.000       0.088       0.164\n",
      "sulphates                0.0905      0.014      6.291      0.000       0.062       0.119\n",
      "alcohol                  0.1999      0.025      7.988      0.000       0.151       0.249\n",
      "==============================================================================\n",
      "Omnibus:                      114.161   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              251.637\n",
      "Skew:                           0.073   Prob(JB):                     2.28e-55\n",
      "Kurtosis:                       4.101   Cond. No.                         138.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_248 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0628\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0222\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0216\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_252 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0553\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_256 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0677\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0244\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0225\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_260 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0646\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_264 (Dense)           (None, 11)                22        \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599\n",
      "Trainable params: 599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_268 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0916\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0259\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_272 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0586\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0235\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0211\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0210\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0208\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0207\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0200\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_276 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0792\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0219\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_280 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0693\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0218\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_284 (Dense)           (None, 11)                33        \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 610\n",
      "Trainable params: 610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0610\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0235\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0204\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0202\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_288 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_292 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0391\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_296 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0502\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_300 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0826\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_304 (Dense)           (None, 11)                44        \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621\n",
      "Trainable params: 621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0356\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_308 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_312 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0383\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_316 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0424\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_320 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0706\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_324 (Dense)           (None, 11)                55        \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0422\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_328 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0372\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0164\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_332 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0566\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_336 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0458\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_340 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0693\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_344 (Dense)           (None, 11)                66        \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.1146\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_348 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0527\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_352 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0460\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_356 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0167\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0159\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0156\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_360 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0394\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_364 (Dense)           (None, 11)                77        \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 654\n",
      "Trainable params: 654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_368 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_370 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 1ms/step - loss: 0.0354\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0170\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_372 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0406\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_376 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0386\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_380 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0527\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_384 (Dense)           (None, 11)                88        \n",
      "                                                                 \n",
      " dense_385 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665\n",
      "Trainable params: 665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.2529\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2529\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_388 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_390 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0473\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_392 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0539\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0182\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_396 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0438\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_400 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0462\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_404 (Dense)           (None, 11)                99        \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0690\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0190\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_408 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_410 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2511\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2511\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2511\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_412 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_416 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0526\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_420 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2505\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_424 (Dense)           (None, 11)                110       \n",
      "                                                                 \n",
      " dense_425 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0750\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0141\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_428 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_430 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0514\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0134\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0134\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_432 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_435 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0547\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0134\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0133\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_436 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0220\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_440 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 3ms/step - loss: 0.0556\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0133\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0133\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0133\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0133\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0133\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0133\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0132\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0132\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0132\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_444 (Dense)           (None, 11)                121       \n",
      "                                                                 \n",
      " dense_445 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698\n",
      "Trainable params: 698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0324\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0144\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_448 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_450 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.0498\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0181\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0151\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0149\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0148\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_452 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_454 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2519\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2519\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2519\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_456 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_459 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2528\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2528\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_460 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_462 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.2505\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.2505\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_464 (Dense)           (None, 11)                132       \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 23)                276       \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 12)                288       \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 709\n",
      "Trainable params: 709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 1s 2ms/step - loss: 0.1198\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0147\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0144\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0139\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "\n",
      "FORWARD SELECTION SUMMARY TABLE:\n",
      "\n",
      "Features In Order Added: ['volatile acidity', 'residual sugar', 'alcohol', 'density', 'pH', 'sulphates', 'free sulfur dioxide', 'fixed acidity', 'total sulfur dioxide', 'chlorides', 'citric acid']\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n",
      "| Num_Features |        r2_cv        |        r2_bar       |        AIC         |        BIC         |\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n",
      "|     1.0      | -2.0466207705055184 | -2.0466207705055184 | -3299.864013671875 | -3299.864013671875 |\n",
      "|     2.0      |  0.0641663521702821 | 0.06397520967685273 | -3811.02099609375  | -3811.02099609375  |\n",
      "|     3.0      |  -1.968253783942973 | -1.9694665536197629 | -3523.842529296875 | -3523.842529296875 |\n",
      "|     4.0      | -1.9744254116184479 |  -1.976248721024834 | -3513.39892578125  | -3513.39892578125  |\n",
      "|     5.0      |  0.2957877029424223 | 0.29521201334744374 |  -4083.599609375   |  -4083.599609375   |\n",
      "|     6.0      | -1.8268955278801975 | -1.8297848323853898 | -3552.528564453125 | -3552.528564453125 |\n",
      "|     7.0      |   -1.8075667125264  | -1.8110108753305625 | -3578.85888671875  | -3578.85888671875  |\n",
      "|     8.0      | 0.32486215252674167 | 0.32389569753035863 | -4118.64306640625  | -4118.64306640625  |\n",
      "|     9.0      |  -6.266994049706656 |   -6.2788852242613  | -2447.737060546875 | -2447.737060546875 |\n",
      "|     10.0     | 0.33439054551759867 | 0.33316499619469736 |  -4128.8369140625  |  -4128.8369140625  |\n",
      "|     11.0     |  -6.166627695530444 |  -6.181292372623814 | -2459.12353515625  | -2459.12353515625  |\n",
      "+--------------+---------------------+---------------------+--------------------+--------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spenc\\Desktop\\UGA_projects\\data_science\\DS2_P2\\python\\Model_Parent_2.py:318: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f48fb14bcc06c66bdca3865fca6a442793c40cec3ae3e13031ed2a63e7b659e"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
