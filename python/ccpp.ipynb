{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from Model_Parent import *\n",
    "from Model_Parent_2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>16.65</td>\n",
       "      <td>49.69</td>\n",
       "      <td>1014.01</td>\n",
       "      <td>91.00</td>\n",
       "      <td>460.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>13.19</td>\n",
       "      <td>39.18</td>\n",
       "      <td>1023.67</td>\n",
       "      <td>66.78</td>\n",
       "      <td>469.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>31.32</td>\n",
       "      <td>74.33</td>\n",
       "      <td>1012.92</td>\n",
       "      <td>36.48</td>\n",
       "      <td>429.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>24.48</td>\n",
       "      <td>69.45</td>\n",
       "      <td>1013.86</td>\n",
       "      <td>62.39</td>\n",
       "      <td>435.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>21.60</td>\n",
       "      <td>62.52</td>\n",
       "      <td>1017.23</td>\n",
       "      <td>67.87</td>\n",
       "      <td>453.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT      V       AP     RH      PE\n",
       "0     14.96  41.76  1024.07  73.17  463.26\n",
       "1     25.18  62.96  1020.04  59.08  444.37\n",
       "2      5.11  39.40  1012.16  92.14  488.56\n",
       "3     20.86  57.32  1010.24  76.64  446.48\n",
       "4     10.82  37.50  1009.23  96.62  473.90\n",
       "...     ...    ...      ...    ...     ...\n",
       "9563  16.65  49.69  1014.01  91.00  460.03\n",
       "9564  13.19  39.18  1023.67  66.78  469.62\n",
       "9565  31.32  74.33  1012.92  36.48  429.57\n",
       "9566  24.48  69.45  1013.86  62.39  435.74\n",
       "9567  21.60  62.52  1017.23  67.87  453.28\n",
       "\n",
       "[9568 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../cleaned_data/CCPP.csv\", index_col=0)\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check to make sure that no columns have perfect colinearity\n",
    "\n",
    "corr_mat = df.corr(method='pearson')\n",
    "sns.heatmap(corr_mat, cmap='vlag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372521</td>\n",
       "      <td>0.291815</td>\n",
       "      <td>0.771591</td>\n",
       "      <td>0.638204</td>\n",
       "      <td>0.569536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662040</td>\n",
       "      <td>0.669039</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.449330</td>\n",
       "      <td>0.319338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093484</td>\n",
       "      <td>0.249822</td>\n",
       "      <td>0.476862</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.904636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.539660</td>\n",
       "      <td>0.568683</td>\n",
       "      <td>0.429349</td>\n",
       "      <td>0.684718</td>\n",
       "      <td>0.347285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.255241</td>\n",
       "      <td>0.216014</td>\n",
       "      <td>0.404355</td>\n",
       "      <td>0.952547</td>\n",
       "      <td>0.710464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>0.420397</td>\n",
       "      <td>0.432918</td>\n",
       "      <td>0.522643</td>\n",
       "      <td>0.877212</td>\n",
       "      <td>0.526755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>0.322380</td>\n",
       "      <td>0.245907</td>\n",
       "      <td>0.761693</td>\n",
       "      <td>0.552547</td>\n",
       "      <td>0.653775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.871352</td>\n",
       "      <td>0.495669</td>\n",
       "      <td>0.146381</td>\n",
       "      <td>0.123311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>0.642210</td>\n",
       "      <td>0.784520</td>\n",
       "      <td>0.518931</td>\n",
       "      <td>0.493700</td>\n",
       "      <td>0.205033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>0.560623</td>\n",
       "      <td>0.661210</td>\n",
       "      <td>0.602326</td>\n",
       "      <td>0.567158</td>\n",
       "      <td>0.437351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AT         V        AP        RH        PE\n",
       "0     0.372521  0.291815  0.771591  0.638204  0.569536\n",
       "1     0.662040  0.669039  0.671863  0.449330  0.319338\n",
       "2     0.093484  0.249822  0.476862  0.892493  0.904636\n",
       "3     0.539660  0.568683  0.429349  0.684718  0.347285\n",
       "4     0.255241  0.216014  0.404355  0.952547  0.710464\n",
       "...        ...       ...       ...       ...       ...\n",
       "9563  0.420397  0.432918  0.522643  0.877212  0.526755\n",
       "9564  0.322380  0.245907  0.761693  0.552547  0.653775\n",
       "9565  0.835977  0.871352  0.495669  0.146381  0.123311\n",
       "9566  0.642210  0.784520  0.518931  0.493700  0.205033\n",
       "9567  0.560623  0.661210  0.602326  0.567158  0.437351\n",
       "\n",
       "[9568 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing old columns names\n",
    "df_col_names = list(df.columns)\n",
    "\n",
    "# Scaling data by min and max in the range of 0 to 1\n",
    "scaler = MinMaxScaler(feature_range = [0, 1])\n",
    "tmp = scaler.fit_transform(df)\n",
    "\n",
    "# Converting scaled values back into dataframe\n",
    "df = pd.DataFrame(tmp, columns=df_col_names)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Data in X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports to build layered neural nets\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of folds in cross validation (kfolds method)\n",
    "cv_folds = 5\n",
    "\n",
    "# Defining number of epochs\n",
    "epo = 10\n",
    "\n",
    "# Defining batch size\n",
    "bs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 2 values in the list are neurons of first 2 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'sigmoid'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 2 values in the list are neurons of first 2 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'tanh'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 2 values in the list are neurons of first 2 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'relu'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 3 values in the list are neurons of first 3 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [25, 10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'sigmoid'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 3 values in the list are neurons of first 3 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [25, 10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'tanh'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 3 values in the list are neurons of first 3 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [25, 10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'relu'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 5 values in the list are neurons of first 5 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [500, 100, 25, 10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'sigmoid'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 5 values in the list are neurons of first 5 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [500, 100, 25, 10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'tanh'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur_list is a list of number of neurons for each layer.\n",
    "# In this case the first 5 values in the list are neurons of first 5 layers.\n",
    "# The last value corresponds to the output layer\n",
    "nur_list = [500, 100, 25, 10, 5, 1]\n",
    "\n",
    "# a_func is the activation function of choice\n",
    "a_func = 'relu'\n",
    "\n",
    "# opt is the optimazation function of choice\n",
    "opt = 'adam'\n",
    "\n",
    "# loss_ is the loss funciton of choice\n",
    "loss_ = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnCrossValidation(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnForwardSelection(X, y, cv_folds, epo, bs, nur_list, a_func, opt, loss_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f48fb14bcc06c66bdca3865fca6a442793c40cec3ae3e13031ed2a63e7b659e"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
