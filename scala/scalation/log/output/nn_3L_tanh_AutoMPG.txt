readFileIntoArray: C:\Users\spenc\Desktop\UGA_projects\data_science\DS2_P2\scala\scalation\data\auto_mpg_fixed_cleaned.csv
load: read 99 data rows so far ...
load: read 199 data rows so far ...
load: read 299 data rows so far ...
load: read in an 392-by-8 matrix from auto_mpg_fixed_cleaned.csv
--------------------------------------
| NeuralNet_3L for AutoMPG with tanh |
--------------------------------------
 scaled: x = 
MatrixD(1.00000,	1.00000,	0.235142,	-0.0869565,	0.0722994,	-0.523810,	-1.00000,
 	1.00000,	1.00000,	0.457364,	0.293478,	0.179473,	-0.583333,	-1.00000,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.0337397,	-0.642857,	-1.00000,
 	1.00000,	1.00000,	0.219638,	0.130435,	0.0320386,	-0.523810,	-1.00000,
 	1.00000,	1.00000,	0.209302,	0.0217391,	0.0411114,	-0.702381,	-1.00000,
 	1.00000,	1.00000,	0.865633,	0.652174,	0.546924,	-0.761905,	-1.00000,
 	1.00000,	1.00000,	0.994832,	0.891304,	0.554295,	-0.880952,	-1.00000,
 	1.00000,	1.00000,	0.922481,	0.836957,	0.530479,	-0.940476,	-1.00000,
 	1.00000,	1.00000,	1.00000,	0.945652,	0.594556,	-0.761905,	-1.00000,
 	1.00000,	1.00000,	0.664083,	0.565217,	0.268500,	-0.940476,	-1.00000,
 	1.00000,	1.00000,	0.627907,	0.347826,	0.105756,	-0.761905,	-1.00000,
 	1.00000,	1.00000,	0.405685,	0.239130,	0.131840,	-1.00000,	-1.00000,
 	1.00000,	1.00000,	0.715762,	0.130435,	0.218032,	-0.821429,	-1.00000,
 	1.00000,	1.00000,	1.00000,	0.945652,	-0.164729,	-0.761905,	-1.00000,
 	1.00000,	-0.600000,	-0.767442,	-0.467391,	-0.569606,	-0.166667,	-1.00000,
 	1.00000,	0.200000,	-0.328165,	-0.467391,	-0.308194,	-0.107143,	-1.00000,
 	1.00000,	0.200000,	-0.322997,	-0.445652,	-0.341650,	-0.107143,	-1.00000,
 	1.00000,	0.200000,	-0.317829,	-0.576087,	-0.447689,	-0.0476190,	-1.00000,
 	1.00000,	-0.600000,	-0.850129,	-0.543478,	-0.706833,	-0.226190,	-1.00000,
 	1.00000,	-0.600000,	-0.850129,	-1.00000,	-0.874114,	0.488095,	-1.00000,
 	1.00000,	-0.600000,	-0.782946,	-0.554348,	-0.399490,	0.130952,	-1.00000,
 	1.00000,	-0.600000,	-0.798450,	-0.521739,	-0.536717,	-0.226190,	-1.00000,
 	1.00000,	-0.600000,	-0.813953,	-0.467391,	-0.567905,	0.130952,	-1.00000,
 	1.00000,	-0.600000,	-0.726098,	-0.271739,	-0.647859,	-0.464286,	-1.00000,
 	1.00000,	0.200000,	-0.322997,	-0.521739,	-0.413099,	-0.166667,	-1.00000,
 	1.00000,	1.00000,	0.509044,	0.836957,	0.702297,	-0.285714,	-1.00000,
 	1.00000,	1.00000,	0.235142,	0.673913,	0.566771,	-0.166667,	-1.00000,
 	1.00000,	1.00000,	0.291990,	0.782609,	0.570173,	-0.345238,	-1.00000,
 	1.00000,	1.00000,	0.219638,	0.597826,	0.768642,	0.250000,	-1.00000,
 	1.00000,	-0.600000,	-0.850129,	-0.543478,	-0.706833,	-0.226190,	-0.833333,
 	1.00000,	-0.600000,	-0.627907,	-0.521739,	-0.630848,	-0.107143,	-0.833333,
 	1.00000,	-0.600000,	-0.767442,	-0.467391,	-0.651262,	-0.285714,	-0.833333,
 	1.00000,	0.200000,	-0.152455,	-0.413043,	-0.421038,	-0.404762,	-0.833333,
 	1.00000,	0.200000,	-0.188630,	-0.358696,	0.0354409,	-0.107143,	-0.833333,
 	1.00000,	0.200000,	-0.0594315,	-0.413043,	-0.0269351,	-0.107143,	-0.833333,
 	1.00000,	0.200000,	-0.0594315,	-0.543478,	-0.0422455,	-0.107143,	-0.833333,
 	1.00000,	0.200000,	-0.152455,	-0.413043,	-0.0501843,	-0.107143,	-0.833333,
 	1.00000,	1.00000,	0.457364,	0.293478,	0.472073,	-0.523810,	-0.833333,
 	1.00000,	1.00000,	0.715762,	0.402174,	0.616671,	-0.583333,	-0.833333,
 	1.00000,	1.00000,	0.462532,	0.163043,	0.440885,	-0.345238,	-0.833333,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.407995,	-0.404762,	-0.833333,
 	1.00000,	1.00000,	0.627907,	0.456522,	0.895095,	-0.583333,	-0.833333,
 	1.00000,	1.00000,	0.715762,	0.347826,	0.776581,	-0.523810,	-0.833333,
 	1.00000,	1.00000,	0.715762,	0.402174,	1.00000,	-0.523810,	-0.833333,
 	1.00000,	0.200000,	-0.0180879,	-0.304348,	-0.235044,	-0.345238,	-0.833333,
 	1.00000,	-0.600000,	-0.627907,	-0.717391,	-0.549192,	0.309524,	-0.833333,
 	1.00000,	0.200000,	-0.0594315,	-0.413043,	-0.0535866,	-0.166667,	-0.833333,
 	1.00000,	0.200000,	-0.0594315,	-0.543478,	-0.134675,	-0.226190,	-0.833333,
 	1.00000,	-0.600000,	-0.720930,	-0.565217,	-0.655798,	-0.285714,	-0.833333,
 	1.00000,	-0.600000,	-0.751938,	-0.521739,	-0.710802,	-0.285714,	-0.833333,
 	1.00000,	-0.600000,	-0.943152,	-0.739130,	-0.738588,	0.369048,	-0.833333,
 	1.00000,	-0.600000,	-0.896641,	-0.673913,	-0.743692,	-0.226190,	-0.833333,
 	1.00000,	-0.600000,	-0.984496,	-0.793478,	-0.909271,	0.309524,	-0.833333,
 	1.00000,	-0.600000,	-0.979328,	-0.750000,	-1.00000,	0.190476,	-0.833333,
 	1.00000,	-0.600000,	-0.850129,	-0.847826,	-0.874681,	0.309524,	-0.833333,
 	1.00000,	-0.600000,	-0.881137,	-0.739130,	-0.806067,	0.488095,	-0.833333,
 	1.00000,	-0.600000,	-0.767442,	-0.467391,	-0.622909,	-0.107143,	-0.666667,
 	1.00000,	-0.600000,	-0.847545,	-0.630435,	-0.709101,	0.0714286,	-0.666667,
 	1.00000,	-0.600000,	-0.850129,	-0.913043,	-0.636518,	0.845238,	-0.666667,
 	1.00000,	-0.600000,	-0.627907,	-0.521739,	-0.549192,	0.369048,	-0.666667,
 	1.00000,	-0.600000,	-0.720930,	-0.565217,	-0.652396,	0.0119048,	-0.666667,
 	1.00000,	1.00000,	0.457364,	0.293478,	0.508931,	-0.523810,	-0.666667,
 	1.00000,	1.00000,	0.715762,	0.402174,	0.571874,	-0.523810,	-0.666667,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.430111,	-0.345238,	-0.666667,
 	1.00000,	1.00000,	0.462532,	0.163043,	0.426708,	-0.404762,	-0.666667,
 	1.00000,	1.00000,	0.219638,	0.130435,	0.167565,	-0.583333,	-0.666667,
 	1.00000,	1.00000,	0.865633,	0.760870,	0.712504,	-0.642857,	-0.666667,
 	1.00000,	1.00000,	0.457364,	0.184783,	0.638219,	-0.345238,	-0.666667,
 	1.00000,	1.00000,	0.457364,	0.239130,	0.612135,	-0.345238,	-0.666667,
 	1.00000,	1.00000,	0.715762,	0.565217,	0.592855,	-0.464286,	-0.666667,
 	1.00000,	-1.00000,	-0.989664,	-0.445652,	-0.593422,	-0.345238,	-0.666667,
 	1.00000,	1.00000,	0.219638,	0.130435,	0.292316,	-0.464286,	-0.666667,
 	1.00000,	1.00000,	0.235142,	-0.0869565,	0.409130,	-0.285714,	-0.666667,
 	1.00000,	1.00000,	0.209302,	0.0217391,	0.520272,	-0.0476190,	-0.666667,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.397221,	-0.285714,	-0.666667,
 	1.00000,	-0.600000,	-0.726098,	-0.282609,	-0.251489,	-0.226190,	-0.666667,
 	1.00000,	-0.600000,	-0.726098,	-0.673913,	-0.490785,	0.190476,	-0.666667,
 	1.00000,	-0.600000,	-0.731266,	-0.554348,	-0.225404,	0.369048,	-0.666667,
 	1.00000,	-0.600000,	-0.855297,	-0.750000,	-0.673377,	0.190476,	-0.666667,
 	1.00000,	-0.600000,	-0.720930,	-0.565217,	-0.556564,	-0.0476190,	-0.666667,
 	1.00000,	-0.600000,	-0.850129,	-0.500000,	-0.617238,	0.0714286,	-0.666667,
 	1.00000,	-0.600000,	-0.731266,	-0.445652,	-0.493621,	-0.226190,	-0.666667,
 	1.00000,	-0.600000,	-0.844961,	-0.630435,	-0.687553,	-0.166667,	-0.666667,
 	1.00000,	-0.600000,	-0.850129,	-0.543478,	-0.723845,	0.0119048,	-0.666667,
 	1.00000,	1.00000,	0.457364,	0.402174,	0.410264,	-0.404762,	-0.500000,
 	1.00000,	1.00000,	0.219638,	0.130435,	0.167565,	-0.583333,	-0.500000,
 	1.00000,	1.00000,	0.457364,	0.0760870,	0.346754,	-0.404762,	-0.500000,
 	1.00000,	1.00000,	0.209302,	-0.0108696,	0.377375,	-0.226190,	-0.500000,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.227105,	-0.464286,	-0.500000,
 	1.00000,	1.00000,	0.865633,	0.652174,	0.893394,	-0.583333,	-0.500000,
 	1.00000,	1.00000,	0.715762,	0.130435,	0.616671,	-0.523810,	-0.500000,
 	1.00000,	1.00000,	0.462532,	0.217391,	0.559399,	-0.404762,	-0.500000,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.487950,	-0.226190,	-0.500000,
 	1.00000,	1.00000,	0.922481,	0.836957,	0.770343,	-0.642857,	-0.500000,
 	1.00000,	1.00000,	1.00000,	0.945652,	0.892827,	-0.642857,	-0.500000,
 	1.00000,	1.00000,	0.509044,	0.402174,	0.252056,	-0.642857,	-0.500000,
 	1.00000,	0.200000,	-0.188630,	-0.358696,	-0.144882,	0.0119048,	-0.500000,
 	1.00000,	0.200000,	-0.0594315,	-0.413043,	-0.0558548,	0.190476,	-0.500000,
 	1.00000,	0.200000,	-0.152455,	-0.413043,	-0.244684,	-0.0476190,	-0.500000,
 	1.00000,	0.200000,	-0.0594315,	-0.543478,	-0.201588,	0.0119048,	-0.500000,
 	1.00000,	0.200000,	-0.328165,	-0.467391,	-0.267933,	-0.0476190,	-0.500000,
 	1.00000,	-0.600000,	-0.850129,	-1.00000,	-0.808903,	0.547619,	-0.500000,
 	1.00000,	1.00000,	0.715762,	0.130435,	0.918911,	-0.285714,	-0.500000,
 	1.00000,	1.00000,	0.715762,	0.315217,	0.867309,	-0.464286,	-0.500000,
 	1.00000,	1.00000,	0.509044,	0.347826,	0.724412,	-0.404762,	-0.500000,
 	1.00000,	1.00000,	0.457364,	0.456522,	0.636518,	-0.464286,	-0.500000,
 	1.00000,	0.200000,	-0.152455,	-0.413043,	-0.333144,	-0.166667,	-0.500000,
 	1.00000,	-0.600000,	-0.850129,	-0.543478,	-0.622342,	0.309524,	-0.500000,
 	1.00000,	-0.600000,	-0.627907,	-0.717391,	-0.553161,	0.369048,	-0.500000,
 	1.00000,	-0.600000,	-0.793282,	-0.478261,	-0.565637,	0.0119048,	-0.500000,
 	1.00000,	-1.00000,	-0.989664,	-0.521739,	-0.710235,	-0.345238,	-0.500000,
 	1.00000,	-0.600000,	-0.720930,	-0.576087,	-0.604763,	0.250000,	-0.500000,
 	1.00000,	0.200000,	-0.550388,	-0.336957,	-0.512900,	-0.285714,	-0.500000,
 	1.00000,	-0.600000,	-0.844961,	-0.521739,	-0.630281,	-0.107143,	-0.500000,
 	1.00000,	1.00000,	0.457364,	0.0760870,	0.400057,	-0.404762,	-0.500000,
 	1.00000,	1.00000,	0.715762,	1.00000,	0.511199,	-0.821429,	-0.500000,
 	1.00000,	-0.600000,	-1.00000,	-0.967391,	-0.855968,	0.369048,	-0.500000,
 	1.00000,	-0.600000,	-0.751938,	-0.684783,	-0.690955,	-0.107143,	-0.500000,
 	1.00000,	-0.600000,	-0.762274,	-0.510870,	-0.450525,	-0.285714,	-0.500000,
 	1.00000,	-0.600000,	-0.726098,	-0.282609,	-0.288347,	-0.107143,	-0.500000,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.0127587,	-0.642857,	-0.500000,
 	1.00000,	-0.600000,	-0.726098,	-0.304348,	-0.406294,	-0.285714,	-0.500000,
 	1.00000,	0.200000,	-0.545220,	-0.173913,	-0.322937,	-0.345238,	-0.500000,
 	1.00000,	1.00000,	0.457364,	0.456522,	0.163028,	-0.642857,	-0.500000,
 	1.00000,	0.200000,	-0.328165,	-0.467391,	-0.155656,	0.0119048,	-0.333333,
 	1.00000,	0.200000,	-0.152455,	-0.413043,	-0.269634,	-0.0476190,	-0.333333,
 	1.00000,	0.200000,	-0.0594315,	-0.413043,	-0.0229657,	0.0714286,	-0.333333,
 	1.00000,	-0.600000,	-0.943152,	-0.771739,	-0.808903,	0.309524,	-0.333333,
 	1.00000,	-0.600000,	-0.720930,	-0.630435,	-0.524809,	0.0119048,	-0.333333,
 	1.00000,	-0.600000,	-0.984496,	-0.793478,	-0.873547,	0.547619,	-0.333333,
 	1.00000,	-0.600000,	-0.627907,	-0.684783,	-0.473207,	0.0714286,	-0.333333,
 	1.00000,	0.200000,	-0.0594315,	-0.413043,	0.229373,	0.0714286,	-0.333333,
 	1.00000,	0.200000,	-0.0180879,	-0.304348,	0.144882,	0.190476,	-0.333333,
 	1.00000,	0.200000,	-0.188630,	-0.358696,	0.134108,	0.0119048,	-0.333333,
 	1.00000,	1.00000,	0.209302,	0.0217391,	0.433513,	-0.285714,	-0.333333,
 	1.00000,	1.00000,	0.457364,	0.130435,	0.749929,	-0.226190,	-0.333333,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.612702,	-0.345238,	-0.333333,
 	1.00000,	1.00000,	0.209302,	0.0217391,	0.715339,	-0.0476190,	-0.333333,
 	1.00000,	1.00000,	0.219638,	0.130435,	0.499291,	-0.107143,	-0.333333,
 	1.00000,	-0.600000,	-0.844961,	-0.597826,	-0.656365,	0.0119048,	-0.333333,
 	1.00000,	-0.600000,	-0.943152,	-0.771739,	-0.801531,	-0.107143,	-0.333333,
 	1.00000,	-0.600000,	-0.850129,	-0.652174,	-0.610434,	-0.226190,	-0.333333,
 	1.00000,	-0.600000,	-0.958656,	-0.934783,	-0.979586,	0.0119048,	-0.333333,
 	1.00000,	-0.600000,	-0.922481,	-0.836957,	-0.778849,	0.309524,	-0.333333,
 	1.00000,	-0.600000,	-0.886305,	-0.684783,	-0.709668,	-0.226190,	-0.333333,
 	1.00000,	-0.600000,	-0.886305,	-0.684783,	-0.719308,	-0.107143,	-0.333333,
 	1.00000,	-0.600000,	-0.751938,	-0.684783,	-0.641055,	-0.285714,	-0.333333,
 	1.00000,	-0.600000,	-0.731266,	-0.445652,	-0.503261,	-0.166667,	-0.333333,
 	1.00000,	-0.600000,	-0.793282,	-0.489130,	-0.558832,	-0.107143,	-0.333333,
 	1.00000,	-0.600000,	-0.943152,	-0.771739,	-0.780550,	-0.0476190,	-0.333333,
 	1.00000,	0.200000,	-0.188630,	-0.467391,	-0.0637936,	-0.0476190,	-0.166667,
 	1.00000,	0.200000,	-0.0594315,	-0.358696,	0.0467820,	-0.0476190,	-0.166667,
 	1.00000,	0.200000,	-0.0594315,	-0.717391,	0.0314715,	0.547619,	-0.166667,
 	1.00000,	0.200000,	-0.0594315,	-0.717391,	-0.123901,	0.369048,	-0.166667,
 	1.00000,	1.00000,	0.715762,	0.347826,	0.732350,	-0.583333,	-0.166667,
 	1.00000,	1.00000,	0.457364,	0.0760870,	0.603062,	-0.285714,	-0.166667,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.635951,	-0.226190,	-0.166667,
 	1.00000,	1.00000,	0.462532,	0.108696,	0.726113,	-0.345238,	-0.166667,
 	1.00000,	0.200000,	-0.157623,	-0.304348,	0.300822,	0.547619,	-0.166667,
 	1.00000,	0.200000,	-0.0594315,	-0.358696,	0.295152,	0.250000,	-0.166667,
 	1.00000,	0.200000,	-0.0180879,	-0.304348,	0.200454,	0.309524,	-0.166667,
 	1.00000,	0.200000,	-0.188630,	-0.467391,	0.231642,	0.309524,	-0.166667,
 	1.00000,	0.200000,	-0.157623,	-0.304348,	-0.191381,	-0.166667,	-0.166667,
 	1.00000,	1.00000,	0.00258398,	-0.304348,	-0.0881769,	-0.345238,	-0.166667,
 	1.00000,	1.00000,	0.209302,	-0.0978261,	-0.117664,	-0.523810,	-0.166667,
 	1.00000,	-0.600000,	-0.850129,	-0.684783,	-0.683584,	-0.0476190,	-0.166667,
 	1.00000,	-0.600000,	-0.627907,	-0.597826,	-0.418202,	0.0714286,	-0.166667,
 	1.00000,	0.200000,	-0.152455,	-0.413043,	-0.262263,	-0.0476190,	-0.166667,
 	1.00000,	-0.600000,	-0.627907,	-0.652174,	-0.444854,	0.250000,	-0.166667,
 	1.00000,	-0.600000,	-0.658915,	-0.456522,	-0.382478,	-0.345238,	-0.166667,
 	1.00000,	-0.600000,	-0.886305,	-0.728261,	-0.654097,	0.0119048,	-0.166667,
 	1.00000,	-0.600000,	-0.736434,	-0.445652,	-0.471506,	0.0714286,	-0.166667,
 	1.00000,	0.200000,	-0.467700,	-0.445652,	-0.222569,	-0.226190,	-0.166667,
 	1.00000,	-0.600000,	-0.886305,	-0.739130,	-0.816274,	-0.285714,	-0.166667,
 	1.00000,	0.200000,	-0.152455,	-0.521739,	-0.0938475,	0.0714286,	-0.166667,
 	1.00000,	-0.600000,	-0.757106,	-0.467391,	-0.387014,	-0.166667,	-0.166667,
 	1.00000,	-0.600000,	-0.731266,	-0.543478,	-0.237879,	0.0714286,	-0.166667,
 	1.00000,	-0.600000,	-0.726098,	-0.434783,	-0.244684,	-0.226190,	-0.166667,
 	1.00000,	-0.600000,	-0.726098,	-0.250000,	-0.400057,	-0.345238,	-0.166667,
 	1.00000,	-0.600000,	-0.881137,	-0.923913,	-0.896796,	0.130952,	-0.166667,
 	1.00000,	-0.600000,	-0.798450,	-0.565217,	-0.517437,	-0.107143,	0.00000,
 	1.00000,	-0.600000,	-0.751938,	-0.619565,	-0.655798,	0.0595238,	0.00000,
 	1.00000,	-0.600000,	-0.627907,	-0.500000,	-0.456195,	-0.178571,	0.00000,
 	1.00000,	-0.600000,	-0.844961,	-0.641304,	-0.635951,	0.154762,	0.00000,
 	1.00000,	-0.600000,	-0.829457,	-0.597826,	-0.666005,	-0.130952,	0.00000,
 	1.00000,	1.00000,	0.224806,	0.0217391,	0.475475,	-0.404762,	0.00000,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.461299,	-0.404762,	0.00000,
 	1.00000,	1.00000,	0.219638,	-0.195652,	0.332010,	-0.297619,	0.00000,
 	1.00000,	1.00000,	0.462532,	0.152174,	0.475475,	-0.428571,	0.00000,
 	1.00000,	0.200000,	-0.188630,	-0.413043,	-0.0813723,	-0.119048,	0.00000,
 	1.00000,	0.200000,	-0.0594315,	-0.358696,	-0.0133258,	-0.226190,	0.00000,
 	1.00000,	0.200000,	-0.317829,	-0.619565,	-0.206691,	0.142857,	0.00000,
 	1.00000,	0.200000,	-0.152455,	-0.521739,	-0.165296,	0.142857,	0.00000,
 	1.00000,	-0.600000,	-0.912145,	-0.934783,	-0.760703,	0.690476,	0.00000,
 	1.00000,	-0.600000,	-0.844961,	-0.847826,	-0.687553,	0.678571,	0.00000,
 	1.00000,	-0.600000,	-0.886305,	-0.739130,	-0.816274,	-0.261905,	0.00000,
 	1.00000,	-0.600000,	-0.881137,	-0.923913,	-0.896796,	0.119048,	0.00000,
 	1.00000,	0.200000,	-0.188630,	-0.413043,	0.155656,	0.154762,	0.00000,
 	1.00000,	0.200000,	-0.0594315,	-0.652174,	0.111993,	0.547619,	0.00000,
 	1.00000,	0.200000,	-0.0594315,	-0.304348,	0.152254,	-0.0238095,	0.00000,
 	1.00000,	0.200000,	-0.0180879,	-0.467391,	-0.104054,	0.166667,	0.00000,
 	1.00000,	-0.600000,	-0.850129,	-0.728261,	-0.879785,	-0.500000,	0.00000,
 	1.00000,	-0.600000,	-0.912145,	-0.739130,	-0.786221,	0.0714286,	0.00000,
 	1.00000,	-0.600000,	-0.850129,	-0.684783,	-0.692657,	-2.22045e-16,	0.00000,
 	1.00000,	-0.600000,	-0.627907,	-0.717391,	-0.460164,	-0.333333,	0.00000,
 	1.00000,	-0.600000,	-0.679587,	-0.391304,	-0.128438,	-0.0833333,	0.00000,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.319535,	-0.380952,	0.00000,
 	1.00000,	-0.600000,	-0.731266,	-0.543478,	-0.0603913,	0.654762,	0.00000,
 	1.00000,	0.200000,	-0.545220,	-0.326087,	-0.253190,	-0.107143,	0.00000,
 	1.00000,	0.200000,	-0.483204,	-0.195652,	0.251489,	0.0357143,	0.00000,
 	1.00000,	1.00000,	0.457364,	0.456522,	0.569039,	-0.511905,	0.00000,
 	1.00000,	1.00000,	0.457364,	0.0760870,	0.384746,	-0.523810,	0.00000,
 	1.00000,	1.00000,	0.209302,	-0.0869565,	0.279841,	-0.166667,	0.00000,
 	1.00000,	1.00000,	0.291990,	0.130435,	0.214630,	-0.285714,	0.00000,
 	1.00000,	-0.600000,	-0.844961,	-0.760870,	-0.755033,	0.250000,	0.166667,
 	1.00000,	-0.600000,	-0.777778,	-0.630435,	-0.692657,	-0.190476,	0.166667,
 	1.00000,	-0.600000,	-0.943152,	-0.869565,	-0.879785,	0.261905,	0.166667,
 	1.00000,	-0.600000,	-0.720930,	-0.456522,	-0.610434,	-0.107143,	0.166667,
 	1.00000,	-0.600000,	-0.912145,	-0.739130,	-0.811738,	0.0476190,	0.166667,
 	1.00000,	1.00000,	0.224806,	0.0760870,	0.285512,	-0.464286,	0.166667,
 	1.00000,	1.00000,	-0.00775194,	-0.304348,	0.387582,	0.309524,	0.166667,
 	1.00000,	1.00000,	0.291990,	0.0760870,	0.432946,	-0.321429,	0.166667,
 	1.00000,	1.00000,	0.209302,	-0.0869565,	0.520839,	-0.178571,	0.166667,
 	1.00000,	0.200000,	-0.0594315,	-0.304348,	0.0813723,	-2.22045e-16,	0.166667,
 	1.00000,	0.200000,	-0.157623,	-0.358696,	0.0275021,	0.0595238,	0.166667,
 	1.00000,	0.200000,	-0.188630,	-0.413043,	0.143748,	0.154762,	0.166667,
 	1.00000,	0.200000,	-0.0594315,	-0.434783,	0.0842075,	0.309524,	0.166667,
 	1.00000,	1.00000,	0.715762,	0.456522,	0.478310,	-0.630952,	0.166667,
 	1.00000,	1.00000,	0.457364,	0.347826,	0.447122,	-0.595238,	0.166667,
 	1.00000,	1.00000,	0.715762,	0.565217,	0.537851,	-0.500000,	0.166667,
 	1.00000,	1.00000,	0.462532,	0.119565,	0.543521,	-0.226190,	0.166667,
 	1.00000,	-0.600000,	-0.850129,	-0.652174,	-0.814573,	-0.226190,	0.166667,
 	1.00000,	-0.600000,	-0.571059,	-0.543478,	-0.360930,	-0.0476190,	0.166667,
 	1.00000,	-0.600000,	-0.850129,	-0.684783,	-0.630281,	0.214286,	0.166667,
 	1.00000,	-0.600000,	-0.627907,	-0.532609,	-0.352424,	-0.0714286,	0.166667,
 	1.00000,	-0.600000,	-0.844961,	-0.815217,	-0.751630,	0.0714286,	0.166667,
 	1.00000,	-0.600000,	-0.844961,	-0.597826,	-0.738021,	-0.0595238,	0.166667,
 	1.00000,	-0.600000,	-0.850129,	-0.771739,	-0.789056,	-2.22045e-16,	0.166667,
 	1.00000,	-0.600000,	-0.850129,	-0.652174,	-0.672810,	-0.273810,	0.166667,
 	1.00000,	0.200000,	-0.596899,	-0.445652,	-0.318401,	-0.226190,	0.166667,
 	1.00000,	-0.600000,	-0.726098,	-0.304348,	-0.440318,	-0.428571,	0.166667,
 	1.00000,	-1.00000,	-0.937984,	-0.304348,	-0.372271,	-0.345238,	0.166667,
 	1.00000,	-0.600000,	-0.886305,	-0.978261,	-0.789056,	0.607143,	0.333333,
 	1.00000,	-0.600000,	-0.844961,	-0.782609,	-0.893961,	-0.238095,	0.333333,
 	1.00000,	-0.600000,	-0.948320,	-0.934783,	-0.789056,	0.357143,	0.333333,
 	1.00000,	-0.600000,	-0.912145,	-0.739130,	-0.740856,	0.261905,	0.333333,
 	1.00000,	-0.600000,	-0.881137,	-0.847826,	-0.893961,	-2.22045e-16,	0.333333,
 	1.00000,	1.00000,	-0.00775194,	-0.304348,	-0.00652112,	-0.107143,	0.333333,
 	1.00000,	1.00000,	0.291990,	0.0217391,	0.203289,	-0.380952,	0.333333,
 	1.00000,	1.00000,	0.209302,	0.0108696,	0.109725,	-0.428571,	0.333333,
 	1.00000,	0.200000,	-0.157623,	-0.358696,	0.0898781,	0.333333,	0.333333,
 	1.00000,	0.200000,	-0.317829,	-0.467391,	-0.125602,	0.214286,	0.333333,
 	1.00000,	0.200000,	-0.317829,	-0.576087,	-0.233343,	-0.0714286,	0.333333,
 	1.00000,	-0.600000,	-0.627907,	-0.543478,	-0.372271,	-0.119048,	0.333333,
 	1.00000,	0.200000,	-0.188630,	-0.413043,	0.0303374,	0.0952381,	0.333333,
 	1.00000,	0.200000,	-0.152455,	-0.521739,	-0.0944145,	0.0952381,	0.333333,
 	1.00000,	0.200000,	-0.157623,	-0.358696,	0.00198469,	-0.0714286,	0.333333,
 	1.00000,	0.200000,	-0.317829,	-0.576087,	-0.173802,	0.0357143,	0.333333,
 	1.00000,	0.200000,	-0.188630,	-0.304348,	0.138078,	0.273810,	0.333333,
 	1.00000,	0.200000,	-0.0180879,	-0.195652,	0.0189963,	-0.154762,	0.333333,
 	1.00000,	1.00000,	0.224806,	0.0760870,	0.0275021,	-0.380952,	0.333333,
 	1.00000,	0.200000,	-0.157623,	0.293478,	0.0388432,	-0.357143,	0.333333,
 	1.00000,	1.00000,	0.209302,	0.0108696,	-0.0972498,	-0.619048,	0.333333,
 	1.00000,	1.00000,	0.291990,	0.0217391,	0.398923,	-0.321429,	0.333333,
 	1.00000,	-0.600000,	-0.844961,	-0.760870,	-0.692657,	0.0119048,	0.333333,
 	1.00000,	-0.600000,	-0.658915,	-0.467391,	-0.463000,	-0.261905,	0.333333,
 	1.00000,	-0.600000,	-0.736434,	-0.445652,	-0.610434,	-0.202381,	0.333333,
 	1.00000,	-0.600000,	-0.808786,	-0.684783,	-0.650128,	-0.226190,	0.333333,
 	1.00000,	-0.600000,	-0.658915,	-0.467391,	-0.488517,	-0.190476,	0.333333,
 	1.00000,	-0.600000,	-0.545220,	-0.358696,	-0.358095,	0.0357143,	0.333333,
 	1.00000,	-0.600000,	-0.571059,	-0.576087,	-0.295719,	0.142857,	0.333333,
 	1.00000,	-0.600000,	-0.736434,	-0.445652,	-0.550893,	-0.178571,	0.333333,
 	1.00000,	-0.200000,	-0.674419,	-0.380435,	-0.309895,	-0.0595238,	0.333333,
 	1.00000,	0.200000,	-0.509044,	-0.141304,	-0.134108,	-0.333333,	0.333333,
 	1.00000,	-0.600000,	-0.726098,	-0.250000,	-0.329742,	-0.0833333,	0.333333,
 	1.00000,	0.200000,	-0.509044,	-0.0543478,	0.0189963,	-0.0714286,	0.333333,
 	1.00000,	-0.600000,	-0.891473,	-0.728261,	-0.786221,	-0.178571,	0.333333,
 	1.00000,	-0.600000,	-0.844961,	-0.760870,	-0.703998,	0.0238095,	0.333333,
 	1.00000,	0.200000,	-0.157623,	-0.250000,	-0.0745676,	-0.119048,	0.500000,
 	1.00000,	0.200000,	-0.317829,	-0.576087,	-0.219166,	0.214286,	0.500000,
 	1.00000,	-0.600000,	-0.627907,	-0.543478,	-0.275872,	0.107143,	0.500000,
 	1.00000,	0.200000,	-0.152455,	-0.521739,	-0.0632265,	0.214286,	0.500000,
 	1.00000,	0.200000,	-0.188630,	-0.304348,	-0.00935639,	0.0238095,	0.500000,
 	1.00000,	1.00000,	0.224806,	-0.0869565,	0.262830,	-0.119048,	0.500000,
 	1.00000,	1.00000,	0.209302,	-0.0978261,	0.197618,	-0.357143,	0.500000,
 	1.00000,	1.00000,	0.462532,	0.00000,	0.328041,	-0.380952,	0.500000,
 	1.00000,	1.00000,	0.291990,	-0.0326087,	0.257159,	-0.142857,	0.500000,
 	1.00000,	1.00000,	0.457364,	0.184783,	0.557698,	-0.178571,	0.500000,
 	1.00000,	1.00000,	0.462532,	0.0434783,	0.384179,	-0.250000,	0.500000,
 	1.00000,	1.00000,	0.0284238,	-0.141304,	0.129572,	-0.166667,	0.500000,
 	1.00000,	1.00000,	0.509044,	0.130435,	0.319535,	-0.404762,	0.500000,
 	1.00000,	-0.600000,	-0.891473,	-0.728261,	-0.823079,	-0.285714,	0.500000,
 	1.00000,	-0.600000,	-0.906977,	-0.793478,	-0.794726,	-0.142857,	0.500000,
 	1.00000,	-0.600000,	-0.844961,	-0.630435,	-0.828750,	-0.238095,	0.500000,
 	1.00000,	-0.600000,	-0.726098,	-0.630435,	-0.400624,	-0.166667,	0.500000,
 	1.00000,	-0.200000,	-0.405685,	-0.663043,	0.0870428,	0.440476,	0.500000,
 	1.00000,	1.00000,	0.457364,	-0.141304,	0.296853,	0.119048,	0.500000,
 	1.00000,	-0.600000,	-0.622739,	-0.728261,	-0.105756,	1.00000,	0.500000,
 	1.00000,	1.00000,	-0.00775194,	-0.521739,	0.0246669,	0.690476,	0.500000,
 	1.00000,	-0.600000,	-0.808786,	-0.739130,	-0.667139,	-0.380952,	0.500000,
 	1.00000,	-0.600000,	-0.808786,	-0.739130,	-0.695492,	-0.178571,	0.500000,
 	1.00000,	-0.600000,	-0.912145,	-0.793478,	-0.769209,	0.333333,	0.500000,
 	1.00000,	-0.600000,	-0.881137,	-0.750000,	-0.706833,	-0.202381,	0.500000,
 	1.00000,	-0.600000,	-0.571059,	-0.521739,	-0.400624,	-0.0476190,	0.500000,
 	1.00000,	0.200000,	-0.457364,	-0.250000,	-0.443153,	-0.607143,	0.500000,
 	1.00000,	0.200000,	-0.457364,	-0.250000,	-0.383612,	-0.416667,	0.500000,
 	1.00000,	-0.600000,	-0.571059,	-0.521739,	-0.465268,	-0.380952,	0.500000,
 	1.00000,	-0.600000,	-0.844961,	-0.673913,	-0.698894,	-0.202381,	0.666667,
 	1.00000,	-0.600000,	-0.891473,	-0.847826,	-0.798696,	0.285714,	0.666667,
 	1.00000,	-0.600000,	-0.844961,	-0.739130,	-0.712504,	-0.107143,	0.666667,
 	1.00000,	-0.600000,	-0.906977,	-0.793478,	-0.769776,	-2.22045e-16,	0.666667,
 	1.00000,	-0.600000,	-0.571059,	-0.521739,	-0.396087,	0.0119048,	0.666667,
 	1.00000,	-0.600000,	-0.627907,	-0.543478,	-0.287213,	0.202381,	0.666667,
 	1.00000,	-0.600000,	-0.571059,	-0.521739,	-0.211795,	0.440476,	0.666667,
 	1.00000,	0.200000,	-0.188630,	-0.521739,	0.00255174,	0.273810,	0.666667,
 	1.00000,	-0.600000,	-0.850129,	-0.652174,	-0.673944,	-0.0714286,	0.666667,
 	1.00000,	-0.600000,	-0.658915,	-0.521739,	-0.377375,	-0.107143,	0.666667,
 	1.00000,	-0.600000,	-0.731266,	-0.684783,	-0.473207,	0.130952,	0.666667,
 	1.00000,	-0.600000,	-0.736434,	-0.500000,	-0.534449,	-0.166667,	0.666667,
 	1.00000,	-0.600000,	-0.793282,	-0.684783,	-0.630281,	-0.142857,	0.666667,
 	1.00000,	-0.600000,	-0.906977,	-0.793478,	-0.718174,	0.178571,	0.666667,
 	1.00000,	-0.600000,	-0.545220,	-0.358696,	-0.326907,	-0.238095,	0.666667,
 	1.00000,	-0.600000,	-0.912145,	-0.793478,	-0.718174,	0.333333,	0.666667,
 	1.00000,	-0.600000,	-0.886305,	-0.978261,	-0.732350,	0.630952,	0.666667,
 	1.00000,	-0.600000,	-0.886305,	-0.978261,	-0.590587,	0.869048,	0.666667,
 	1.00000,	-0.200000,	-0.726098,	-0.771739,	-0.241849,	0.416667,	0.666667,
 	1.00000,	-0.600000,	-0.596899,	-0.771739,	-0.0717324,	0.642857,	0.666667,
 	1.00000,	-0.600000,	-0.881137,	-0.771739,	-0.865608,	-0.309524,	0.666667,
 	1.00000,	-0.600000,	-0.850129,	-0.771739,	-0.698327,	0.190476,	0.666667,
 	1.00000,	-0.600000,	-0.891473,	-0.826087,	-0.868443,	-0.130952,	0.666667,
 	1.00000,	0.200000,	-0.483204,	-0.0652174,	-0.264531,	-0.595238,	0.666667,
 	1.00000,	-1.00000,	-0.989664,	-0.413043,	-0.542387,	-0.464286,	0.666667,
 	1.00000,	-0.600000,	-0.720930,	-0.543478,	-0.497023,	-0.154762,	0.666667,
 	1.00000,	-0.600000,	-0.798450,	-0.717391,	-0.616104,	0.0714286,	0.666667,
 	1.00000,	-0.600000,	-0.653747,	-0.586957,	-0.502694,	-0.0833333,	0.833333,
 	1.00000,	-0.600000,	-0.571059,	-0.586957,	-0.420471,	-2.22045e-16,	0.833333,
 	1.00000,	-0.600000,	-0.545220,	-0.500000,	-0.428976,	-0.238095,	0.833333,
 	1.00000,	0.200000,	-0.457364,	-0.304348,	-0.369436,	-0.452381,	0.833333,
 	1.00000,	-0.600000,	-0.653747,	-0.586957,	-0.562234,	-0.416667,	0.833333,
 	1.00000,	-0.600000,	-0.943152,	-0.869565,	-0.919478,	0.0595238,	0.833333,
 	1.00000,	-0.600000,	-0.906977,	-0.804348,	-0.851432,	-2.22045e-16,	0.833333,
 	1.00000,	-0.600000,	-0.932817,	-0.847826,	-0.916643,	-0.0357143,	0.833333,
 	1.00000,	-0.600000,	-0.850129,	-0.771739,	-0.743692,	0.166667,	0.833333,
 	1.00000,	-0.600000,	-0.912145,	-0.793478,	-0.794726,	0.357143,	0.833333,
 	1.00000,	-0.600000,	-0.891473,	-0.826087,	-0.752197,	0.107143,	0.833333,
 	1.00000,	-0.600000,	-0.881137,	-0.760870,	-0.789056,	-0.0476190,	0.833333,
 	1.00000,	-0.600000,	-0.808786,	-0.815217,	-0.658633,	-0.178571,	0.833333,
 	1.00000,	-0.600000,	-0.844961,	-0.793478,	-0.755033,	-0.0238095,	0.833333,
 	1.00000,	-0.600000,	-0.844961,	-0.793478,	-0.565069,	0.511905,	0.833333,
 	1.00000,	-0.600000,	-0.808786,	-0.695652,	-0.672810,	-0.261905,	0.833333,
 	1.00000,	-0.600000,	-0.798450,	-0.684783,	-0.661469,	-0.238095,	0.833333,
 	1.00000,	-0.600000,	-0.793282,	-0.684783,	-0.582081,	0.0476190,	0.833333,
 	1.00000,	-0.600000,	-0.736434,	-0.413043,	-0.431812,	-0.190476,	0.833333,
 	1.00000,	-0.600000,	-0.731266,	-0.695652,	-0.420471,	0.226190,	0.833333,
 	1.00000,	-0.600000,	-0.622739,	-0.630435,	-0.0830734,	0.476190,	0.833333,
 	1.00000,	0.200000,	-0.602067,	-0.673913,	-0.122767,	0.380952,	0.833333,
 	1.00000,	0.200000,	-0.483204,	-0.239130,	-0.270201,	-0.452381,	0.833333,
 	1.00000,	0.200000,	-0.596899,	-0.195652,	-0.253190,	-0.309524,	0.833333,
 	1.00000,	0.200000,	-0.157623,	-0.304348,	0.0218316,	-0.0714286,	0.833333,
 	1.00000,	1.00000,	0.457364,	-0.358696,	0.197618,	0.309524,	0.833333,
 	1.00000,	0.200000,	-0.317829,	-0.543478,	-0.179473,	0.0833333,	0.833333,
 	1.00000,	0.200000,	-0.188630,	-0.576087,	0.0501843,	0.0238095,	0.833333,
 	1.00000,	-0.600000,	-0.772610,	-0.543478,	-0.437482,	0.380952,	1.00000,
 	1.00000,	-0.600000,	-0.772610,	-0.543478,	-0.417635,	0.261905,	1.00000,
 	1.00000,	-0.600000,	-0.772610,	-0.543478,	-0.556564,	0.190476,	1.00000,
 	1.00000,	-0.600000,	-0.772610,	-0.576087,	-0.454494,	-0.0238095,	1.00000,
 	1.00000,	-0.600000,	-0.653747,	-0.586957,	-0.482847,	-0.0476190,	1.00000,
 	1.00000,	-0.600000,	-0.571059,	-0.521739,	-0.363765,	0.190476,	1.00000,
 	1.00000,	-0.600000,	-0.627907,	-0.500000,	-0.290048,	-2.22045e-16,	1.00000,
 	1.00000,	-0.600000,	-0.808786,	-0.695652,	-0.791891,	-0.130952,	1.00000,
 	1.00000,	-0.600000,	-0.881137,	-0.760870,	-0.766374,	0.214286,	1.00000,
 	1.00000,	-0.600000,	-0.881137,	-0.760870,	-0.797562,	0.142857,	1.00000,
 	1.00000,	-0.600000,	-0.808786,	-0.815217,	-0.709668,	-0.202381,	1.00000,
 	1.00000,	-0.600000,	-0.844961,	-0.739130,	-0.709668,	0.107143,	1.00000,
 	1.00000,	-0.600000,	-0.731266,	-0.543478,	-0.689821,	-0.226190,	1.00000,
 	1.00000,	-0.600000,	-0.798450,	-0.684783,	-0.664304,	-0.226190,	1.00000,
 	1.00000,	-0.600000,	-0.793282,	-0.739130,	-0.641622,	0.0595238,	1.00000,
 	1.00000,	-0.600000,	-0.881137,	-0.771739,	-0.800397,	-0.166667,	1.00000,
 	1.00000,	-0.600000,	-0.881137,	-0.771739,	-0.800397,	-0.0833333,	1.00000,
 	1.00000,	-0.600000,	-0.881137,	-0.771739,	-0.783385,	-0.0238095,	1.00000,
 	1.00000,	0.200000,	-0.416021,	-0.304348,	-0.244684,	-2.22045e-16,	1.00000,
 	1.00000,	0.200000,	0.00258398,	-0.576087,	-0.204990,	0.0714286,	1.00000,
 	1.00000,	-0.600000,	-0.545220,	-0.500000,	-0.448823,	-0.226190,	1.00000,
 	1.00000,	0.200000,	-0.152455,	-0.282609,	-0.307060,	-0.202381,	1.00000,
 	1.00000,	-0.600000,	-0.607235,	-0.456522,	-0.403459,	-0.297619,	1.00000,
 	1.00000,	-0.600000,	-0.653747,	-0.586957,	-0.570740,	-0.404762,	1.00000,
 	1.00000,	-0.600000,	-0.571059,	-0.521739,	-0.241849,	0.107143,	1.00000,
 	1.00000,	-0.600000,	-0.627907,	-0.565217,	-0.332577,	-0.0952381,	1.00000,
 	1.00000,	-0.600000,	-0.850129,	-0.934783,	-0.706833,	0.976190,	1.00000,
 	1.00000,	-0.600000,	-0.653747,	-0.586957,	-0.613269,	-0.571429,	1.00000,
 	1.00000,	-0.600000,	-0.731266,	-0.641304,	-0.426141,	0.261905,	1.00000,
 	1.00000,	-0.600000,	-0.736434,	-0.608696,	-0.372271,	0.357143,	1.00000) 
 scaled y = 
MatrixD(18.0000,
 	15.0000,
 	18.0000,
 	16.0000,
 	17.0000,
 	15.0000,
 	14.0000,
 	14.0000,
 	14.0000,
 	15.0000,
 	15.0000,
 	14.0000,
 	15.0000,
 	14.0000,
 	24.0000,
 	22.0000,
 	18.0000,
 	21.0000,
 	27.0000,
 	26.0000,
 	25.0000,
 	24.0000,
 	25.0000,
 	26.0000,
 	21.0000,
 	10.0000,
 	10.0000,
 	11.0000,
 	9.00000,
 	27.0000,
 	28.0000,
 	25.0000,
 	19.0000,
 	16.0000,
 	17.0000,
 	19.0000,
 	18.0000,
 	14.0000,
 	14.0000,
 	14.0000,
 	14.0000,
 	12.0000,
 	13.0000,
 	13.0000,
 	18.0000,
 	22.0000,
 	19.0000,
 	18.0000,
 	23.0000,
 	28.0000,
 	30.0000,
 	30.0000,
 	31.0000,
 	35.0000,
 	27.0000,
 	26.0000,
 	24.0000,
 	25.0000,
 	23.0000,
 	20.0000,
 	21.0000,
 	13.0000,
 	14.0000,
 	15.0000,
 	14.0000,
 	17.0000,
 	11.0000,
 	13.0000,
 	12.0000,
 	13.0000,
 	19.0000,
 	15.0000,
 	13.0000,
 	13.0000,
 	14.0000,
 	18.0000,
 	22.0000,
 	21.0000,
 	26.0000,
 	22.0000,
 	28.0000,
 	23.0000,
 	28.0000,
 	27.0000,
 	13.0000,
 	14.0000,
 	13.0000,
 	14.0000,
 	15.0000,
 	12.0000,
 	13.0000,
 	13.0000,
 	14.0000,
 	13.0000,
 	12.0000,
 	13.0000,
 	18.0000,
 	16.0000,
 	18.0000,
 	18.0000,
 	23.0000,
 	26.0000,
 	11.0000,
 	12.0000,
 	13.0000,
 	12.0000,
 	18.0000,
 	20.0000,
 	21.0000,
 	22.0000,
 	18.0000,
 	19.0000,
 	21.0000,
 	26.0000,
 	15.0000,
 	16.0000,
 	29.0000,
 	24.0000,
 	20.0000,
 	19.0000,
 	15.0000,
 	24.0000,
 	20.0000,
 	11.0000,
 	20.0000,
 	19.0000,
 	15.0000,
 	31.0000,
 	26.0000,
 	32.0000,
 	25.0000,
 	16.0000,
 	16.0000,
 	18.0000,
 	16.0000,
 	13.0000,
 	14.0000,
 	14.0000,
 	14.0000,
 	29.0000,
 	26.0000,
 	26.0000,
 	31.0000,
 	32.0000,
 	28.0000,
 	24.0000,
 	26.0000,
 	24.0000,
 	26.0000,
 	31.0000,
 	19.0000,
 	18.0000,
 	15.0000,
 	15.0000,
 	16.0000,
 	15.0000,
 	16.0000,
 	14.0000,
 	17.0000,
 	16.0000,
 	15.0000,
 	18.0000,
 	21.0000,
 	20.0000,
 	13.0000,
 	29.0000,
 	23.0000,
 	20.0000,
 	23.0000,
 	24.0000,
 	25.0000,
 	24.0000,
 	18.0000,
 	29.0000,
 	19.0000,
 	23.0000,
 	23.0000,
 	22.0000,
 	25.0000,
 	33.0000,
 	28.0000,
 	25.0000,
 	25.0000,
 	26.0000,
 	27.0000,
 	17.5000,
 	16.0000,
 	15.5000,
 	14.5000,
 	22.0000,
 	22.0000,
 	24.0000,
 	22.5000,
 	29.0000,
 	24.5000,
 	29.0000,
 	33.0000,
 	20.0000,
 	18.0000,
 	18.5000,
 	17.5000,
 	29.5000,
 	32.0000,
 	28.0000,
 	26.5000,
 	20.0000,
 	13.0000,
 	19.0000,
 	19.0000,
 	16.5000,
 	16.5000,
 	13.0000,
 	13.0000,
 	13.0000,
 	31.5000,
 	30.0000,
 	36.0000,
 	25.5000,
 	33.5000,
 	17.5000,
 	17.0000,
 	15.5000,
 	15.0000,
 	17.5000,
 	20.5000,
 	19.0000,
 	18.5000,
 	16.0000,
 	15.5000,
 	15.5000,
 	16.0000,
 	29.0000,
 	24.5000,
 	26.0000,
 	25.5000,
 	30.5000,
 	33.5000,
 	30.0000,
 	30.5000,
 	22.0000,
 	21.5000,
 	21.5000,
 	43.1000,
 	36.1000,
 	32.8000,
 	39.4000,
 	36.1000,
 	19.9000,
 	19.4000,
 	20.2000,
 	19.2000,
 	20.5000,
 	20.2000,
 	25.1000,
 	20.5000,
 	19.4000,
 	20.6000,
 	20.8000,
 	18.6000,
 	18.1000,
 	19.2000,
 	17.7000,
 	18.1000,
 	17.5000,
 	30.0000,
 	27.5000,
 	27.2000,
 	30.9000,
 	21.1000,
 	23.2000,
 	23.8000,
 	23.9000,
 	20.3000,
 	17.0000,
 	21.6000,
 	16.2000,
 	31.5000,
 	29.5000,
 	21.5000,
 	19.8000,
 	22.3000,
 	20.2000,
 	20.6000,
 	17.0000,
 	17.6000,
 	16.5000,
 	18.2000,
 	16.9000,
 	15.5000,
 	19.2000,
 	18.5000,
 	31.9000,
 	34.1000,
 	35.7000,
 	27.4000,
 	25.4000,
 	23.0000,
 	27.2000,
 	23.9000,
 	34.2000,
 	34.5000,
 	31.8000,
 	37.3000,
 	28.4000,
 	28.8000,
 	26.8000,
 	33.5000,
 	41.5000,
 	38.1000,
 	32.1000,
 	37.2000,
 	28.0000,
 	26.4000,
 	24.3000,
 	19.1000,
 	34.3000,
 	29.8000,
 	31.3000,
 	37.0000,
 	32.2000,
 	46.6000,
 	27.9000,
 	40.8000,
 	44.3000,
 	43.4000,
 	36.4000,
 	30.0000,
 	44.6000,
 	33.8000,
 	29.8000,
 	32.7000,
 	23.7000,
 	35.0000,
 	32.4000,
 	27.2000,
 	26.6000,
 	25.8000,
 	23.5000,
 	30.0000,
 	39.1000,
 	39.0000,
 	35.1000,
 	32.3000,
 	37.0000,
 	37.7000,
 	34.1000,
 	34.7000,
 	34.4000,
 	29.9000,
 	33.0000,
 	33.7000,
 	32.4000,
 	32.9000,
 	31.6000,
 	28.1000,
 	30.7000,
 	25.4000,
 	24.2000,
 	22.4000,
 	26.6000,
 	20.2000,
 	17.6000,
 	28.0000,
 	27.0000,
 	34.0000,
 	31.0000,
 	29.0000,
 	27.0000,
 	24.0000,
 	36.0000,
 	37.0000,
 	31.0000,
 	38.0000,
 	36.0000,
 	36.0000,
 	36.0000,
 	34.0000,
 	38.0000,
 	32.0000,
 	38.0000,
 	25.0000,
 	38.0000,
 	26.0000,
 	22.0000,
 	32.0000,
 	36.0000,
 	27.0000,
 	27.0000,
 	44.0000,
 	32.0000,
 	28.0000,
 	31.0000)
auto_optimize: etaI = (2.5E-4,0.004)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 2.5E-4, result = (4128.586150186999,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 4.84375E-4, result = (3226.455874966141,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 7.1875E-4, result = (3003.725318177499,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 9.53125E-4, result = (2899.831142838144,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.0011875, result = (2830.556774926232,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.001421875, result = (2792.2094267297084,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.00165625, result = (2771.882950814147,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.001890625, result = (2756.5539600620928,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.002125, result = (2741.847884370535,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.0023593750000000004, result = (2741.2943718485453,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.0025937499999999997, result = (2727.9839951120584,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.002828125, result = (2730.5819016698906,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.0030625, result = (2682.732810344044,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.0032968750000000003, result = (2662.5189200406758,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.0035312499999999997, result = (2636.287948659901,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.003765625, result = (2625.019456248947,400)
optimize3: bSize = 20, nB = 19
auto_optimize: eta = 0.004, result = (2612.5438609194553,400)
ending epoch = (2612.5438609194553,400)

REPORT
    ----------------------------------------------------------------------------
    modelName  mn  = NeuralNet_3L_tanh
    ----------------------------------------------------------------------------
    hparameter hp  = HyperParameter (HashMap(lambda -> (0.01,0.01), maxEpochs -> (400,400), eta -> (0.1,0.1), nu -> (0.9,0.9), upLimit -> (4,4), beta -> (0.9,0.9), bSize -> (20,20)))
    ----------------------------------------------------------------------------
    features   fn  = Array(intercept, cylinders, displacement, horsepower, weight, acceleration, modelyear)
    ----------------------------------------------------------------------------
    parameter  bb  = Array(b.w = 
MatrixD(0.976151,	0.718169,	1.18131,	0.891772,	-0.511898,	0.450032,	0.623084,	1.04257,	0.995835,	0.740492,	0.320426,	1.39495,	0.133325,	0.712118,	0.880542,
 	0.174703,	0.339898,	-0.764711,	0.0752123,	0.0749937,	1.16140,	0.319628,	-0.211930,	-0.0209376,	-0.369225,	0.232511,	-0.539815,	-0.392775,	-0.300156,	0.288942,
 	-0.130118,	0.184826,	1.19897,	-0.0848754,	0.0677737,	0.795010,	0.168842,	-0.0120265,	-0.0807720,	0.228900,	0.186164,	0.276915,	-0.216081,	-0.0556299,	-0.0994729,
 	-0.0800727,	-0.384541,	1.31655,	-0.0784811,	-0.360951,	0.601656,	-0.219781,	-0.0418694,	0.0492424,	-0.329664,	-0.429628,	1.53043,	-0.259337,	-0.0853436,	-0.214675,
 	-0.100381,	-0.277299,	1.53851,	-0.0948926,	-0.807539,	0.711163,	-0.326986,	-0.141533,	-0.194123,	-0.508713,	-0.501290,	1.21889,	-0.425134,	-0.320751,	-0.153393,
 	-0.0689305,	-0.127064,	0.122848,	-0.00567890,	0.0675411,	0.544906,	-0.000652081,	-0.0522798,	0.00288482,	-0.461699,	-0.134958,	-0.520784,	0.000882689,	-0.475559,	-0.155684,
 	0.100365,	-0.0134705,	0.137607,	-0.0502051,	2.37743,	0.108057,	-0.151967,	0.0879674,	0.0249815,	0.387688,	-0.0817345,	-1.35939,	0.232473,	0.439901,	0.0485719) 
 b.b = VectorD(0.881949,	0.637390,	1.17534,	0.803671,	-0.565637,	0.445686,	0.547235,	0.918206,	0.878396,	0.630270,	0.253447,	1.39096,	0.101088,	0.628825,	0.781398), b.w = 
MatrixD(2.50958,
 	2.35037,
 	-3.82749,
 	2.59155,
 	2.69419,
 	-1.97571,
 	2.46536,
 	2.84232,
 	3.11602,
 	3.11566,
 	2.34403,
 	-3.90660,
 	0.928109,
 	2.51440,
 	2.92281) 
 b.b = VectorD(4.38508))
    ----------------------------------------------------------------------------
    fitMap     qof = 
		rSq 	 -> VectorD(0.890317) 
		rSqBar 	 -> VectorD(0.888323) 
		sst 	 -> VectorD(23819.0) 
		sse 	 -> VectorD(2612.54) 
		mse0 	 -> VectorD(6.66465) 
		rmse 	 -> VectorD(2.58160) 
		mae 	 -> VectorD(1.86170) 
		dfm 	 -> VectorD(7.00000) 
		df 	 -> VectorD(385.000) 
		fStat 	 -> VectorD(446.444) 
		aic 	 -> VectorD(-912.000) 
		bic 	 -> VectorD(-880.230) 
		mape 	 -> VectorD(7.90842) 
		smape 	 -> VectorD(7.81370) 

    ----------------------------------------------------------------------------
        
Run + title
--------------------
| Cross-Validation |
--------------------
DEBUG @ PredictorMV.crossValidate: fold 0: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (1986.740980689323,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.50958,
 	2.35037,
 	-3.82749,
 	2.59155,
 	2.69419,
 	-1.97571,
 	2.46536,
 	2.84232,
 	3.11602,
 	3.11566,
 	2.34403,
 	-3.90660,
 	0.928109,
 	2.51440,
 	2.92281) 
 b.b = VectorD(4.38508)
DEBUG @ PredictorMV.crossValidate: fold 0: qof = 
MatrixD(0.889724,
 	0.887719,
 	4731.23,
 	521.742,
 	6.68900,
 	2.58631,
 	1.71137,
 	7.00000,
 	385.000,
 	443.748,
 	-168.796,
 	-149.942,
 	6.99854,
 	7.06086)
DEBUG @ PredictorMV.crossValidate: fold 1: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (1826.7456642674501,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.50958,
 	2.35037,
 	-3.82749,
 	2.59155,
 	2.69419,
 	-1.97571,
 	2.46536,
 	2.84232,
 	3.11602,
 	3.11566,
 	2.34403,
 	-3.90660,
 	0.928109,
 	2.51440,
 	2.92281) 
 b.b = VectorD(4.38508)
DEBUG @ PredictorMV.crossValidate: fold 1: qof = 
MatrixD(0.865478,
 	0.863032,
 	4472.51,
 	601.653,
 	7.71350,
 	2.77732,
 	2.09304,
 	7.00000,
 	385.000,
 	353.854,
 	-174.792,
 	-155.938,
 	9.31406,
 	9.01596)
DEBUG @ PredictorMV.crossValidate: fold 2: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (1837.148598103774,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.50958,
 	2.35037,
 	-3.82749,
 	2.59155,
 	2.69419,
 	-1.97571,
 	2.46536,
 	2.84232,
 	3.11602,
 	3.11566,
 	2.34403,
 	-3.90660,
 	0.928109,
 	2.51440,
 	2.92281) 
 b.b = VectorD(4.38508)
DEBUG @ PredictorMV.crossValidate: fold 2: qof = 
MatrixD(0.881603,
 	0.879451,
 	4664.26,
 	552.232,
 	7.07990,
 	2.66081,
 	1.92788,
 	7.00000,
 	385.000,
 	409.541,
 	-171.084,
 	-152.230,
 	7.95875,
 	7.81798)
DEBUG @ PredictorMV.crossValidate: fold 3: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (1921.5021185833052,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.50958,
 	2.35037,
 	-3.82749,
 	2.59155,
 	2.69419,
 	-1.97571,
 	2.46536,
 	2.84232,
 	3.11602,
 	3.11566,
 	2.34403,
 	-3.90660,
 	0.928109,
 	2.51440,
 	2.92281) 
 b.b = VectorD(4.38508)
DEBUG @ PredictorMV.crossValidate: fold 3: qof = 
MatrixD(0.901407,
 	0.899614,
 	3962.82,
 	390.707,
 	5.00907,
 	2.23809,
 	1.66731,
 	7.00000,
 	385.000,
 	502.848,
 	-158.963,
 	-140.109,
 	7.68924,
 	7.49777)
DEBUG @ PredictorMV.crossValidate: fold 4: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (1809.3420291866735,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.50958,
 	2.35037,
 	-3.82749,
 	2.59155,
 	2.69419,
 	-1.97571,
 	2.46536,
 	2.84232,
 	3.11602,
 	3.11566,
 	2.34403,
 	-3.90660,
 	0.928109,
 	2.51440,
 	2.92281) 
 b.b = VectorD(4.38508)
DEBUG @ PredictorMV.crossValidate: fold 4: qof = 
MatrixD(0.904995,
 	0.903268,
 	5671.58,
 	538.827,
 	6.90804,
 	2.62832,
 	1.90755,
 	7.00000,
 	385.000,
 	523.918,
 	-170.078,
 	-151.224,
 	7.55244,
 	7.63120)
-----------------------------------------------
| showQofStatTable: Statistical Table for QoF |
-----------------------------------------------
|        name |   num |        min |        max |       mean |      stdev |   interval |
----------------------------------------------------------------------------------------
|         rSq |     5 |      0.865 |      0.905 |      0.889 |      0.016 |      0.020 |
|      rSqBar |     5 |      0.863 |      0.903 |      0.887 |      0.016 |      0.020 |
|         sst |     5 |   3962.818 |   5671.580 |   4700.481 |    620.767 |    770.935 |
|         sse |     5 |    390.707 |    601.653 |    521.032 |     78.700 |     97.739 |
|        mse0 |     5 |      5.009 |      7.714 |      6.680 |      1.009 |      1.253 |
|        rmse |     5 |      2.238 |      2.777 |      2.578 |      0.203 |      0.252 |
|         mae |     5 |      1.667 |      2.093 |      1.861 |      0.173 |      0.215 |
|         dfm |     5 |      7.000 |      7.000 |      7.000 |      0.000 |      0.000 |
|          df |     5 |    385.000 |    385.000 |    385.000 |      0.000 |      0.000 |
|       fStat |     5 |    353.854 |    523.918 |    446.782 |     69.147 |     85.874 |
|         aic |     5 |   -174.792 |   -158.963 |   -168.742 |      5.906 |      7.334 |
|         bic |     5 |   -155.938 |   -140.109 |   -149.889 |      5.906 |      7.334 |
|        mape |     5 |      6.999 |      9.314 |      7.903 |      0.863 |      1.072 |
|       smape |     5 |      7.061 |      9.016 |      7.805 |      0.732 |      0.909 |
----------------------------------------------------------------------------------------
----------------------------------------
| Feature Selection Technique: Forward |
----------------------------------------
-------------------------------------------------------------------------------------
| forwardSelAll: (l = 0) INITIAL variable (0, intercept) => cols = LinkedHashSet(0) |
-------------------------------------------------------------------------------------
optimize3: bSize = 20, nB = 19
ending epoch = (8881.119710919735,400)
optimize3: bSize = 20, nB = 19
ending epoch = (7413.916022269484,400)
optimize3: bSize = 20, nB = 19
ending epoch = (7235.223150043087,400)
optimize3: bSize = 20, nB = 19
ending epoch = (6809.720765527009,400)
optimize3: bSize = 20, nB = 19
ending epoch = (18954.628349577506,400)
optimize3: bSize = 20, nB = 19
ending epoch = (14839.083156316787,400)
DEBUG @ PredictorMV.crossValidate: fold 0: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (5483.380143105579,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(6.12879,
 	5.99046,
 	-6.51548,
 	5.89479,
 	5.18425) 
 b.b = VectorD(6.43950)
DEBUG @ PredictorMV.crossValidate: fold 0: qof = 
MatrixD(0.723689,
 	0.722272,
 	4731.23,
 	1307.29,
 	16.7602,
 	4.09392,
 	2.82084,
 	2.00000,
 	390.000,
 	510.726,
 	-214.642,
 	-207.572,
 	11.7344,
 	11.7895)
DEBUG @ PredictorMV.crossValidate: fold 1: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (5564.286348679812,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(6.17133,
 	6.10597,
 	-6.39076,
 	6.01109,
 	5.30007) 
 b.b = VectorD(6.56434)
DEBUG @ PredictorMV.crossValidate: fold 1: qof = 
MatrixD(0.731455,
 	0.730078,
 	4472.51,
 	1201.07,
 	15.3983,
 	3.92407,
 	3.11625,
 	2.00000,
 	390.000,
 	531.136,
 	-211.584,
 	-204.513,
 	13.8623,
 	13.3770)
DEBUG @ PredictorMV.crossValidate: fold 2: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (4975.631716803271,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(6.22142,
 	6.18587,
 	-6.48433,
 	6.09108,
 	5.37993) 
 b.b = VectorD(6.63512)
DEBUG @ PredictorMV.crossValidate: fold 2: qof = 
MatrixD(0.611788,
 	0.609797,
 	4664.26,
 	1810.72,
 	23.2144,
 	4.81813,
 	3.57968,
 	2.00000,
 	390.000,
 	307.303,
 	-229.140,
 	-222.069,
 	15.1347,
 	14.2936)
DEBUG @ PredictorMV.crossValidate: fold 3: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (5608.707255103614,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(6.05692,
 	6.17045,
 	-6.01184,
 	6.07685,
 	5.36517) 
 b.b = VectorD(6.62573)
DEBUG @ PredictorMV.crossValidate: fold 3: qof = 
MatrixD(0.700206,
 	0.698669,
 	3962.82,
 	1188.03,
 	15.2311,
 	3.90271,
 	3.06675,
 	2.00000,
 	390.000,
 	455.447,
 	-211.208,
 	-204.138,
 	13.9255,
 	13.3487)
DEBUG @ PredictorMV.crossValidate: fold 4: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (5329.379116749104,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(6.26425,
 	6.30663,
 	-6.16318,
 	6.21205,
 	5.50058) 
 b.b = VectorD(6.73576)
DEBUG @ PredictorMV.crossValidate: fold 4: qof = 
MatrixD(0.741089,
 	0.739761,
 	5671.58,
 	1468.43,
 	18.8261,
 	4.33890,
 	2.88256,
 	2.00000,
 	390.000,
 	558.155,
 	-219.283,
 	-212.213,
 	10.6457,
 	10.9374)
------------------------------------------------------------------------------------------------------
| forwardSelAll: (l = 1) ADD variable (4, weight) => cols = LinkedHashSet(0, 4) @ 0.7126393094957946 |
------------------------------------------------------------------------------------------------------
optimize3: bSize = 20, nB = 19
ending epoch = (6615.918458999112,400)
optimize3: bSize = 20, nB = 19
ending epoch = (6501.634603777489,400)
optimize3: bSize = 20, nB = 19
ending epoch = (5817.512041043297,400)
optimize3: bSize = 20, nB = 19
ending epoch = (6468.237989618131,400)
optimize3: bSize = 20, nB = 19
ending epoch = (3338.972237579018,400)
DEBUG @ PredictorMV.crossValidate: fold 0: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2625.0836030613705,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(5.41903,
 	5.24937,
 	2.72450,
 	5.48697,
 	5.65382,
 	4.56149,
 	5.24126) 
 b.b = VectorD(5.96140)
DEBUG @ PredictorMV.crossValidate: fold 0: qof = 
MatrixD(0.856460,
 	0.855353,
 	4731.23,
 	679.121,
 	8.70668,
 	2.95071,
 	1.92806,
 	3.00000,
 	389.000,
 	773.682,
 	-187.086,
 	-177.659,
 	8.05226,
 	8.11538)
DEBUG @ PredictorMV.crossValidate: fold 1: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2578.874688685159,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(5.54859,
 	5.37919,
 	2.90040,
 	5.62114,
 	5.65825,
 	4.73009,
 	5.37373) 
 b.b = VectorD(6.08990)
DEBUG @ PredictorMV.crossValidate: fold 1: qof = 
MatrixD(0.860807,
 	0.859733,
 	4472.51,
 	622.543,
 	7.98133,
 	2.82512,
 	2.17338,
 	3.00000,
 	389.000,
 	801.893,
 	-183.765,
 	-174.338,
 	10.1155,
 	9.57534)
DEBUG @ PredictorMV.crossValidate: fold 2: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2499.6140458887535,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(5.58430,
 	5.41502,
 	2.92158,
 	5.65824,
 	5.47687,
 	5.00972,
 	5.41032) 
 b.b = VectorD(6.12375)
DEBUG @ PredictorMV.crossValidate: fold 2: qof = 
MatrixD(0.853964,
 	0.852837,
 	4664.26,
 	681.152,
 	8.73271,
 	2.95512,
 	2.11509,
 	3.00000,
 	389.000,
 	758.240,
 	-187.205,
 	-177.779,
 	9.04464,
 	8.83633)
DEBUG @ PredictorMV.crossValidate: fold 3: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2584.837945753967,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(5.43388,
 	5.26452,
 	2.73517,
 	5.50492,
 	5.25136,
 	5.14579,
 	5.25842) 
 b.b = VectorD(5.98310)
DEBUG @ PredictorMV.crossValidate: fold 3: qof = 
MatrixD(0.860250,
 	0.859172,
 	3962.82,
 	553.804,
 	7.10006,
 	2.66459,
 	1.99334,
 	3.00000,
 	389.000,
 	798.180,
 	-179.730,
 	-170.303,
 	9.17335,
 	8.83915)
DEBUG @ PredictorMV.crossValidate: fold 4: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2289.8914722348777,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(5.42098,
 	5.25178,
 	2.70471,
 	5.49403,
 	5.12564,
 	5.40342,
 	5.24677) 
 b.b = VectorD(5.97539)
DEBUG @ PredictorMV.crossValidate: fold 4: qof = 
MatrixD(0.853435,
 	0.852305,
 	5671.58,
 	831.256,
 	10.6571,
 	3.26453,
 	2.31793,
 	3.00000,
 	389.000,
 	755.037,
 	-196.017,
 	-186.590,
 	9.00709,
 	9.23554)
------------------------------------------------------------------------------------------------------------
| forwardSelAll: (l = 2) ADD variable (6, modelyear) => cols = LinkedHashSet(0, 4, 6) @ 0.8587378316186695 |
------------------------------------------------------------------------------------------------------------
optimize3: bSize = 20, nB = 19
ending epoch = (3278.5118920556524,400)
optimize3: bSize = 20, nB = 19
ending epoch = (3236.9886472376297,400)
optimize3: bSize = 20, nB = 19
ending epoch = (2959.469033755109,400)
optimize3: bSize = 20, nB = 19
ending epoch = (3016.4368294458154,400)
DEBUG @ PredictorMV.crossValidate: fold 0: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2332.7916061990036,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(4.11371,
 	4.08068,
 	-4.07561,
 	4.04753,
 	2.33651,
 	-5.11056,
 	3.75236,
 	4.22648,
 	4.42627) 
 b.b = VectorD(4.69051)
DEBUG @ PredictorMV.crossValidate: fold 0: qof = 
MatrixD(0.880340,
 	0.879107,
 	4731.23,
 	566.138,
 	7.25818,
 	2.69410,
 	1.87424,
 	4.00000,
 	388.000,
 	713.633,
 	-178.010,
 	-166.226,
 	7.94615,
 	7.94845)
DEBUG @ PredictorMV.crossValidate: fold 1: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2176.268758397982,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(4.16156,
 	4.13181,
 	-4.28489,
 	4.09079,
 	2.38626,
 	-5.28415,
 	3.80093,
 	4.27380,
 	4.47583) 
 b.b = VectorD(4.73804)
DEBUG @ PredictorMV.crossValidate: fold 1: qof = 
MatrixD(0.839583,
 	0.837930,
 	4472.51,
 	717.466,
 	9.19828,
 	3.03287,
 	2.27327,
 	4.00000,
 	388.000,
 	507.676,
 	-188.033,
 	-176.249,
 	10.4353,
 	9.95235)
DEBUG @ PredictorMV.crossValidate: fold 2: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2229.9834642990127,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(4.20402,
 	4.17481,
 	-4.43625,
 	4.13472,
 	2.43064,
 	-5.11012,
 	3.84317,
 	4.31670,
 	4.51916) 
 b.b = VectorD(4.77200)
DEBUG @ PredictorMV.crossValidate: fold 2: qof = 
MatrixD(0.856484,
 	0.855004,
 	4664.26,
 	669.397,
 	8.58201,
 	2.92951,
 	2.18012,
 	4.00000,
 	388.000,
 	578.882,
 	-184.849,
 	-173.065,
 	9.22109,
 	8.96488)
DEBUG @ PredictorMV.crossValidate: fold 3: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2439.7074140041036,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(4.17222,
 	4.14186,
 	-4.30101,
 	4.07063,
 	2.39648,
 	-5.02419,
 	3.81181,
 	4.28406,
 	4.48637) 
 b.b = VectorD(4.74234)
DEBUG @ PredictorMV.crossValidate: fold 3: qof = 
MatrixD(0.890675,
 	0.889548,
 	3962.82,
 	433.236,
 	5.55430,
 	2.35676,
 	1.78783,
 	4.00000,
 	388.000,
 	790.262,
 	-169.208,
 	-157.424,
 	8.25514,
 	8.04826)
DEBUG @ PredictorMV.crossValidate: fold 4: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2194.999098142204,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(4.15242,
 	4.12372,
 	-4.42293,
 	4.02504,
 	2.37736,
 	-4.86787,
 	3.79230,
 	4.26359,
 	4.46692) 
 b.b = VectorD(4.73086)
DEBUG @ PredictorMV.crossValidate: fold 4: qof = 
MatrixD(0.875931,
 	0.874652,
 	5671.58,
 	703.667,
 	9.02137,
 	3.00356,
 	2.22145,
 	4.00000,
 	388.000,
 	684.823,
 	-187.119,
 	-175.335,
 	8.74500,
 	8.88717)
----------------------------------------------------------------------------------------------------------------
| forwardSelAll: (l = 3) ADD variable (3, horsepower) => cols = LinkedHashSet(0, 4, 6, 3) @ 0.8744708071885341 |
----------------------------------------------------------------------------------------------------------------
optimize3: bSize = 20, nB = 19
ending epoch = (2975.700328458317,400)
optimize3: bSize = 20, nB = 19
ending epoch = (2938.344284189591,400)
optimize3: bSize = 20, nB = 19
ending epoch = (2915.422025016056,400)
DEBUG @ PredictorMV.crossValidate: fold 0: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2221.1923700458956,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.72013,
 	3.30337,
 	-3.31432,
 	3.37508,
 	1.67809,
 	-3.97956,
 	3.06748,
 	3.87048,
 	3.73327,
 	3.59926,
 	3.79301) 
 b.b = VectorD(4.19309)
DEBUG @ PredictorMV.crossValidate: fold 0: qof = 
MatrixD(0.881612,
 	0.880082,
 	4731.23,
 	560.121,
 	7.18104,
 	2.67975,
 	1.83324,
 	5.00000,
 	387.000,
 	576.383,
 	-175.587,
 	-161.447,
 	7.63254,
 	7.65901)
DEBUG @ PredictorMV.crossValidate: fold 1: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2082.1206910221795,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.78787,
 	3.35294,
 	-3.47266,
 	3.42528,
 	1.72729,
 	-4.14467,
 	3.11883,
 	3.92256,
 	3.78329,
 	3.64932,
 	4.04253) 
 b.b = VectorD(4.24570)
DEBUG @ PredictorMV.crossValidate: fold 1: qof = 
MatrixD(0.843712,
 	0.841693,
 	4472.51,
 	699.000,
 	8.96154,
 	2.99358,
 	2.28322,
 	5.00000,
 	387.000,
 	417.840,
 	-184.925,
 	-170.784,
 	10.3151,
 	9.86973)
DEBUG @ PredictorMV.crossValidate: fold 2: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2103.11451540793,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.72179,
 	3.28414,
 	-3.55762,
 	3.35831,
 	1.65961,
 	-4.25596,
 	3.05010,
 	3.85548,
 	3.71588,
 	3.58053,
 	3.97206) 
 b.b = VectorD(4.17480)
DEBUG @ PredictorMV.crossValidate: fold 2: qof = 
MatrixD(0.863158,
 	0.861390,
 	4664.26,
 	638.269,
 	8.18293,
 	2.86058,
 	2.14654,
 	5.00000,
 	387.000,
 	488.214,
 	-180.841,
 	-166.701,
 	9.06913,
 	8.86409)
DEBUG @ PredictorMV.crossValidate: fold 3: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2266.1220423146087,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.74604,
 	3.29570,
 	-3.70471,
 	3.36939,
 	1.66848,
 	-4.35047,
 	3.06028,
 	3.86617,
 	3.72867,
 	3.59056,
 	4.12320) 
 b.b = VectorD(4.19633)
DEBUG @ PredictorMV.crossValidate: fold 3: qof = 
MatrixD(0.887436,
 	0.885982,
 	3962.82,
 	446.069,
 	5.71883,
 	2.39141,
 	1.79038,
 	5.00000,
 	387.000,
 	610.212,
 	-167.919,
 	-153.779,
 	8.22889,
 	7.95925)
DEBUG @ PredictorMV.crossValidate: fold 4: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2091.851846139098,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.75516,
 	3.30605,
 	-3.79240,
 	3.37609,
 	1.67677,
 	-4.37480,
 	3.06763,
 	3.87210,
 	3.73702,
 	3.59638,
 	4.18295) 
 b.b = VectorD(4.19219)
DEBUG @ PredictorMV.crossValidate: fold 4: qof = 
MatrixD(0.889547,
 	0.888120,
 	5671.58,
 	626.442,
 	8.03131,
 	2.83396,
 	2.10957,
 	5.00000,
 	387.000,
 	623.351,
 	-180.046,
 	-165.906,
 	8.32431,
 	8.43728)
---------------------------------------------------------------------------------------------------------------------
| forwardSelAll: (l = 4) ADD variable (5, acceleration) => cols = LinkedHashSet(0, 4, 6, 3, 5) @ 0.8760195732015725 |
---------------------------------------------------------------------------------------------------------------------
optimize3: bSize = 20, nB = 19
ending epoch = (2880.3586015694477,400)
optimize3: bSize = 20, nB = 19
ending epoch = (2924.2693381460977,400)
DEBUG @ PredictorMV.crossValidate: fold 0: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2195.126713185264,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.20765,
 	3.15623,
 	-4.12473,
 	2.92956,
 	3.02127,
 	2.47868,
 	2.86919,
 	3.66168,
 	3.44373,
 	3.46584,
 	2.88934,
 	0.169180,
 	-3.03253) 
 b.b = VectorD(4.10784)
DEBUG @ PredictorMV.crossValidate: fold 0: qof = 
MatrixD(0.879234,
 	0.877357,
 	4731.23,
 	571.373,
 	7.32529,
 	2.70653,
 	1.81427,
 	6.00000,
 	386.000,
 	468.377,
 	-174.339,
 	-157.842,
 	7.55504,
 	7.58972)
DEBUG @ PredictorMV.crossValidate: fold 1: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2054.9415645288004,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.31264,
 	3.26041,
 	-4.25566,
 	3.03358,
 	3.09689,
 	2.67779,
 	2.97773,
 	3.76918,
 	3.54779,
 	3.57133,
 	3.01274,
 	0.149578,
 	-3.13846) 
 b.b = VectorD(4.20742)
DEBUG @ PredictorMV.crossValidate: fold 1: qof = 
MatrixD(0.848524,
 	0.846170,
 	4472.51,
 	677.477,
 	8.68561,
 	2.94714,
 	2.21631,
 	6.00000,
 	386.000,
 	360.377,
 	-181.559,
 	-165.063,
 	9.91572,
 	9.52223)
DEBUG @ PredictorMV.crossValidate: fold 2: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2048.9688639605406,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.39192,
 	3.34080,
 	-4.24793,
 	3.11314,
 	3.24547,
 	2.80652,
 	3.05448,
 	3.85067,
 	3.62680,
 	3.65012,
 	3.09110,
 	0.0923728,
 	-3.35307) 
 b.b = VectorD(4.28644)
DEBUG @ PredictorMV.crossValidate: fold 2: qof = 
MatrixD(0.868544,
 	0.866501,
 	4664.26,
 	613.145,
 	7.86084,
 	2.80372,
 	2.04429,
 	6.00000,
 	386.000,
 	425.057,
 	-177.182,
 	-160.685,
 	8.61149,
 	8.40024)
DEBUG @ PredictorMV.crossValidate: fold 3: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2122.727769645546,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.44390,
 	3.39278,
 	-4.46768,
 	3.16454,
 	3.29036,
 	3.01343,
 	3.10425,
 	3.90367,
 	3.67837,
 	3.70090,
 	3.14467,
 	0.0660657,
 	-3.45615) 
 b.b = VectorD(4.33356)
DEBUG @ PredictorMV.crossValidate: fold 3: qof = 
MatrixD(0.890459,
 	0.888756,
 	3962.82,
 	434.092,
 	5.56528,
 	2.35908,
 	1.72895,
 	6.00000,
 	386.000,
 	522.965,
 	-164.998,
 	-148.501,
 	7.89898,
 	7.65128)
DEBUG @ PredictorMV.crossValidate: fold 4: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (1977.418073034032,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(3.52605,
 	3.47068,
 	-4.49295,
 	3.24326,
 	3.46580,
 	3.21738,
 	3.18311,
 	3.98179,
 	3.75695,
 	3.77860,
 	3.21754,
 	0.0724441,
 	-3.72590) 
 b.b = VectorD(4.41550)
DEBUG @ PredictorMV.crossValidate: fold 4: qof = 
MatrixD(0.901924,
 	0.900400,
 	5671.58,
 	556.243,
 	7.13132,
 	2.67045,
 	2.01401,
 	6.00000,
 	386.000,
 	591.624,
 	-173.310,
 	-156.813,
 	8.06769,
 	8.17302)
---------------------------------------------------------------------------------------------------------------------
| forwardSelAll: (l = 5) ADD variable (1, cylinders) => cols = LinkedHashSet(0, 4, 6, 3, 5, 1) @ 0.8771933407335313 |
---------------------------------------------------------------------------------------------------------------------
optimize3: bSize = 20, nB = 19
ending epoch = (2828.9533431918508,400)
DEBUG @ PredictorMV.crossValidate: fold 0: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2141.1608182732784,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(1.99045,
 	2.55225,
 	-3.01978,
 	2.68050,
 	1.12937,
 	-3.32517,
 	1.71289,
 	3.24585,
 	3.00206,
 	3.25656,
 	1.60582,
 	-3.64182,
 	-2.59439,
 	2.60065,
 	2.91389) 
 b.b = VectorD(3.89997)
DEBUG @ PredictorMV.crossValidate: fold 0: qof = 
MatrixD(0.878958,
 	0.876757,
 	4731.23,
 	572.678,
 	7.34203,
 	2.70962,
 	1.84501,
 	7.00000,
 	385.000,
 	399.388,
 	-172.434,
 	-153.581,
 	7.80335,
 	7.82847)
DEBUG @ PredictorMV.crossValidate: fold 1: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2006.403270865544,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.09891,
 	2.66200,
 	-3.12172,
 	2.78960,
 	1.22369,
 	-3.53611,
 	1.81813,
 	3.35524,
 	3.11159,
 	3.38968,
 	1.71597,
 	-3.80448,
 	-2.67457,
 	2.71855,
 	3.02355) 
 b.b = VectorD(4.01247)
DEBUG @ PredictorMV.crossValidate: fold 1: qof = 
MatrixD(0.849312,
 	0.846572,
 	4472.51,
 	673.954,
 	8.64043,
 	2.93946,
 	2.22135,
 	7.00000,
 	385.000,
 	309.993,
 	-179.454,
 	-160.600,
 	9.89421,
 	9.51721)
DEBUG @ PredictorMV.crossValidate: fold 2: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2041.159907631114,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.12039,
 	2.68386,
 	-3.30520,
 	2.81118,
 	1.23435,
 	-3.52875,
 	1.83823,
 	3.37459,
 	3.13195,
 	3.41019,
 	1.73244,
 	-3.87490,
 	-2.85904,
 	2.73682,
 	3.04602) 
 b.b = VectorD(4.04125)
DEBUG @ PredictorMV.crossValidate: fold 2: qof = 
MatrixD(0.874611,
 	0.872331,
 	4664.26,
 	584.846,
 	7.49803,
 	2.73825,
 	2.00180,
 	7.00000,
 	385.000,
 	383.636,
 	-173.278,
 	-154.424,
 	8.42956,
 	8.21697)
DEBUG @ PredictorMV.crossValidate: fold 3: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (2088.999533805374,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.15914,
 	2.72101,
 	-3.39713,
 	2.85225,
 	1.25740,
 	-3.63460,
 	1.87497,
 	3.41275,
 	3.17026,
 	3.45632,
 	1.76752,
 	-4.10013,
 	-2.93764,
 	2.77501,
 	3.08499) 
 b.b = VectorD(4.08016)
DEBUG @ PredictorMV.crossValidate: fold 3: qof = 
MatrixD(0.883110,
 	0.880985,
 	3962.82,
 	463.214,
 	5.93865,
 	2.43693,
 	1.79180,
 	7.00000,
 	385.000,
 	415.527,
 	-164.847,
 	-145.994,
 	8.21853,
 	7.92568)
DEBUG @ PredictorMV.crossValidate: fold 4: test set size = 78
DEBUG @ PredictorMV.validate: test set size = 78
optimize3: bSize = 20, nB = 15
ending epoch = (1974.091346116372,400)
DEBUG @ PredictorMV.validate: parameters b = b.w = 
MatrixD(2.22703,
 	2.78334,
 	-3.63231,
 	2.92108,
 	1.31395,
 	-3.77699,
 	1.94863,
 	3.47606,
 	3.23522,
 	3.52224,
 	1.83016,
 	-4.14442,
 	-3.13635,
 	2.84846,
 	3.14907) 
 b.b = VectorD(4.15269)
DEBUG @ PredictorMV.crossValidate: fold 4: qof = 
MatrixD(0.904017,
 	0.902272,
 	5671.58,
 	544.373,
 	6.97914,
 	2.64181,
 	2.00201,
 	7.00000,
 	385.000,
 	518.021,
 	-170.472,
 	-151.619,
 	7.98468,
 	8.08852)
---------------------------------------------------------------------------------------------------------------------------
| forwardSelAll: (l = 6) ADD variable (2, displacement) => cols = LinkedHashSet(0, 4, 6, 3, 5, 1, 2) @ 0.8790717642110069 |
---------------------------------------------------------------------------------------------------------------------------
k = 7, n = 7
Run + title
x-axis: minX = 0.0, maxX = 6.0
y-axis: minY = 70.0, maxY = 89.0
rSq = 
MatrixD(71.4105,	71.2639,	70.1645,
 	85.9819,	85.8738,	85.6983,
 	87.5752,	87.4471,	86.8603,
 	87.7601,	87.6020,	87.3093,
 	87.9073,	87.7193,	87.7737,
 	88.1231,	87.9072,	87.8002)
